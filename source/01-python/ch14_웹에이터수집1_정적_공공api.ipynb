{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cea0cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:100% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:22pt;}\n",
       "div.output {font-size:22pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:22pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:22pt;padding:5px;}\n",
       "table.dataframe{font-size:22px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:100% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:22pt;}\n",
    "div.output {font-size:22pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:22pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:22pt;padding:5px;}\n",
    "table.dataframe{font-size:22px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1335187",
   "metadata": {},
   "source": [
    "# ch14. 웹데이터 수집\n",
    "## 1절. BeautifulSoup과 parser\n",
    "pip install bs4 아나콘다를 설치하면 자동 설치되는 패키지 7500개에 포함\n",
    "\n",
    "* 공식 Documentation : https://beautiful-soup-4.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e40b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내 local pc의 파일을 url처럼 접근\n",
    "import requests\n",
    "from requests_file import FileAdapter # file://프로토콜을 다루기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c913386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=requests.Session() # HTTP 요청처리하는 세션 객체\n",
    "s.mount(\"file://\",FileAdapter())\n",
    "# file://경로로 들어오면 이 요청은 c:(로컬 파일)을 접근\n",
    "response=s.get('file:///ai/lecNote/01_python/data/ch14_sample.html')\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f14fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘 접근하였습니다.\n"
     ]
    }
   ],
   "source": [
    "if response:\n",
    "    print('잘 접근하였습니다.')\n",
    "else:\n",
    "    print('접근을 못했습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code\n",
    "    # 200: 정상\n",
    "    # 404: 없는 페이지\n",
    "    # 406: get,post 오류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef497862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90 \\xec\\x95\\x88\\xec\\x9d\\x98 \\xeb\\x82\\xb4\\xec\\x9a\\xa9</div>\\r\\n  <p>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90\\xec\\x84\\x9c \\xed\\x99\\x9c\\xec\\x9a\\xa9\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</p>\\r\\n  <div class=\"contents\">\\r\\n    \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\xa5\\xbc \\xec\\x96\\xb4\\xeb\\x96\\xbb\\xea\\xb2\\x8c \\xec\\x9e\\x91\\xec\\x84\\xb1\\xed\\x95\\x98\\xeb\\x8a\\x90\\xeb\\x83\\x90\\xec\\x97\\x90 \\xeb\\x94\\xb0\\xeb\\x9d\\xbc\\r\\n    <span>\\xeb\\x8b\\xa4\\xeb\\xa5\\xb8<b>\\xec\\x9a\\x94\\xec\\x86\\x8c\\xea\\xb0\\x80 \\xeb\\xb0\\x98\\xed\\x99\\x98</b></span>\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4\\r\\n  </div>\\r\\n  <div>CSS \\xec\\x84\\xa0\\xed\\x83\\x9d\\xec\\x9e\\x90\\xeb\\x8a\\x94 \\xeb\\x8b\\xa4\\xec\\x96\\x91\\xed\\x95\\x9c \\xea\\xb3\\xb3\\xec\\x97\\x90 <b>\\xed\\x99\\x9c\\xec\\x9a\\xa9</b>\\xeb\\x90\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content # 바이너리 형식의 html 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e686e078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n  <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n  <div class=\"contents\">\\r\\n    선택자를 어떻게 작성하느냐에 따라\\r\\n    <span>다른<b>요소가 반환</b></span>됩니다\\r\\n  </div>\\r\\n  <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4484b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n</head>\\r\\n<body>\\r\\n  <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\\r\\n  <h1 class=\"css\">Hi, CSS</h1>\\r\\n  <div id=\"subject\">subject 선택자 안의 내용</div>\\r\\n  <p>CSS 선택자는 다양한 곳에서 활용됩니다</p>\\r\\n  <div class=\"contents\">\\r\\n    선택자를 어떻게 작성하느냐에 따라\\r\\n    <span>다른<b>요소가 반환</b></span>됩니다\\r\\n  </div>\\r\\n  <div>CSS 선택자는 다양한 곳에 <b>활용</b>됩니다</div>\\r\\n</body>\\r\\n</html>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text # html 파일의 텍스트 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857503bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 파싱\n",
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(response.content,# response.text\n",
    "                  \"html.parser\")\n",
    "# soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c631fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "el.text : Hello, CSS\n",
      "el.string : Hello, CSS\n",
      "el의 속성들 : {'class': ['greeting', 'css'], 'id': 'text'}\n",
      "el의 id속성 : text\n",
      "el의 id속성 : text\n",
      "el의 href속성 : None\n",
      "el의 태그이름 : h1\n"
     ]
    }
   ],
   "source": [
    "# soup.select_one('선택자') : 해당선택자 처음 하나만\n",
    "el = soup.select_one('h1') # 처음 나오는 h1태그 하나만\n",
    "print('el :', el)\n",
    "print('el.text :', el.text)\n",
    "print('el.string :', el.string)\n",
    "print('el의 속성들 :', el.attrs)\n",
    "print('el의 id속성 :', el.attrs['id']) # el.attrs은 딕셔너리\n",
    "print('el의 id속성 :', el.attrs.get('id'))\n",
    "print('el의 href속성 :', el.attrs.get('href'))\n",
    "print('el의 태그이름 :', el.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd289617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "els : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "els의 text들 : ['Hello, CSS', 'Hi, CSS']\n",
      "els의 string들 : ['Hello, CSS', 'Hi, CSS']\n",
      "els의 속성들 : [{'class': ['greeting', 'css'], 'id': 'text'}, {'class': ['css']}]\n"
     ]
    }
   ],
   "source": [
    "# soup.select('선택자') : 해당 선택자 모두 \n",
    "els = soup.select('h1') # h1태그를 list\n",
    "print('els :', els)\n",
    "print('els의 text들 :', [el.text for el in els])\n",
    "print('els의 string들 :', [el.string for el in els])\n",
    "print('els의 속성들 :', [el.attrs for el in els])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755f68cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_one : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "\n",
      "select_one : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n",
      "find : <h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>\n"
     ]
    }
   ],
   "source": [
    "# soup.find(태그, 속성) : soup.select_one('선택자')와 유사\n",
    "print('select_one :', soup.select_one('h1.css') )\n",
    "print('find :', soup.find('h1', {'class':'css'}) ) # soup.select_one('h1.css')\n",
    "print('find :', soup.find('h1', class_='css') )\n",
    "print()\n",
    "print('select_one :', soup.select_one('h1#text') )\n",
    "print('find :', soup.find('h1', {'id':'text'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c2568a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n"
     ]
    }
   ],
   "source": [
    "# soup.find_all(태그, 속성) : soup.select('선택자')와 유사\n",
    "print('select :', soup.select('h1.css'))\n",
    "print('find_all :', soup.find_all('h1', class_='css'))\n",
    "print('find_all :', soup.find_all('h1', {'class':'css'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a37a4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>, <span>다른<b>요소가 반환</b></span>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>]\n",
      "find_all : [<h1 class=\"greeting css\" id=\"text\">Hello, CSS</h1>, <h1 class=\"css\">Hi, CSS</h1>, <span>다른<b>요소가 반환</b></span>]\n"
     ]
    }
   ],
   "source": [
    "print('select :', soup.select('h1.css, span'))\n",
    "print('find_all :', soup.find_all(['h1', 'span'], {'class':'css'}))\n",
    "print('find_all :', soup.find_all('h1', class_='css') + \\\n",
    "                     soup.find_all('span'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef56b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select(빈 list) : []\n",
      "select_one(None) : None\n",
      "find_all(빈 list) : []\n",
      "find(None) : None\n"
     ]
    }
   ],
   "source": [
    "# 없는 엘리먼트 찾기\n",
    "print('select(빈 list) :', soup.select('a.css'))\n",
    "print('select_one(None) :', soup.select_one('a.css'))\n",
    "print('find_all(빈 list) :', soup.find_all('a', {'class', 'css'}))\n",
    "print('find(None) :', soup.find('a', {'class':'css'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb9d84",
   "metadata": {},
   "source": [
    "# 2절 정적 웹 데이터 수집(정적 웹크롤링)\n",
    "## 2.1 BeautifulSoup을 활용한 html 웹 데이터 수집\n",
    "- 1) 환율 정보 가져오기(네이버증권-> 시장지표)\n",
    "- https://finance.naver.com/marketindex/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8512b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 허용범위는 사이트마다 ~/robots.txt에서 확인\n",
    " # Allow:/ - 사이트의 모든 경로(/)에 대한 크롤링 허용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c45ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://finance.naver.com/marketindex/'\n",
    "response=requests.get(url)\n",
    "# response.status_code\n",
    "# response.text/response.content.decode('cp949')\n",
    "soup=BeautifulSoup(response.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993132f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "url='https://finance.naver.com/marketindex/'\n",
    "response=urlopen(url)\n",
    "response.status\n",
    "# response.read().decode / response.read().decode('cp949')\n",
    "soup=BeautifulSoup(response,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf8d5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1454.0, 942.93, 1682.13, 204.13, 153.42, 1.1564, 1.3161, 99.47, 59.75, 1699.82, 4009.8, 190498.44]\n"
     ]
    }
   ],
   "source": [
    "# div.head_info > span.value (find함수)\n",
    "prices = []\n",
    "headinfos = soup.find_all('div', class_='head_info')\n",
    "for headinfo in headinfos:\n",
    "    price = headinfo.find('span', class_='value')\n",
    "    # print(price.text.replace(',', ''))\n",
    "    prices.append(float(''.join(price.text.split(',') ) ) )\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e7cc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1454.0, 942.93, 1682.13, 204.13, 153.42, 1.1564, 1.3161, 99.47, 59.75, 1699.82, 4009.8, 190498.44]\n"
     ]
    }
   ],
   "source": [
    "# div.head_info > span.value (select함수)\n",
    "prices = soup.select('div.head_info > span.value')\n",
    "print([float(p.text.replace(',','')) for p in prices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3831d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD\t일본 JPY(100엔)\t유럽연합 EUR\t중국 CNY\t달러/일본 엔\t유로/달러\t영국 파운드/달러\t달러인덱스\tWTI\t휘발유\t국제 금\t국내 금\t"
     ]
    }
   ],
   "source": [
    "titles = soup.select('h3.h_lst > span.blind')\n",
    "for t in titles:\n",
    "        print(t.text, end='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04beb806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['원', '원', '원', '원', '엔', '달러', '달러', '', '달러', '원', '달러', '원']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = soup.select('div.head_info > span > span.blind')\n",
    "units = [unit.text for unit in units]\n",
    "units.insert(7, '') # 7번째에 '' 추가\n",
    "units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a08eea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하락\t하락\t하락\t하락\t상승\t하락\t상승\t하락\t상승\t상승\t상승\t상승\t"
     ]
    }
   ],
   "source": [
    "statuses = soup.select('div.head_info > span.blind')\n",
    "for idx in range(len(statuses)):\n",
    "    print(statuses[idx].text, end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ddf74dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 12, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles), len(prices), len(units), len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1a66330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD : 1,454.00원 - 하락\n",
      "일본 JPY(100엔) : 942.93원 - 하락\n",
      "유럽연합 EUR : 1,682.13원 - 하락\n",
      "중국 CNY : 204.13원 - 하락\n",
      "달러/일본 엔 : 153.4200엔 - 상승\n",
      "유로/달러 : 1.1564달러 - 하락\n",
      "영국 파운드/달러 : 1.3161달러 - 상승\n",
      "달러인덱스 : 99.4700 - 하락\n",
      "WTI : 59.75달러 - 상승\n",
      "휘발유 : 1699.82원 - 상승\n",
      "국제 금 : 4009.8달러 - 상승\n",
      "국내 금 : 190498.44원 - 상승\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(titles)):\n",
    "    print(\"{} : {}{} - {}\".format(titles[idx].text,\n",
    "                                 prices[idx].text,\n",
    "                                 units[idx],\n",
    "                                 statuses[idx].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a3a529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD : 1,454.00원 -하락\n",
      "일본 JPY(100엔) : 942.93원 -하락\n",
      "유럽연합 EUR : 1,682.13원 -하락\n",
      "중국 CNY : 204.13원 -하락\n",
      "달러/일본 엔 : 153.4200엔 -상승\n",
      "유로/달러 : 1.1564달러 -하락\n",
      "영국 파운드/달러 : 1.3161달러 -상승\n",
      "달러인덱스 : 99.4700 -하락\n",
      "WTI : 59.75달러 -상승\n",
      "휘발유 : 1699.82원 -상승\n",
      "국제 금 : 4009.8달러 -상승\n",
      "국내 금 : 190498.44원 -상승\n"
     ]
    }
   ],
   "source": [
    "for title, price, unit, status in zip(titles, prices, units, statuses):\n",
    "    print(\"{} : {}{} -{}\".format(title.text,\n",
    "                                price.text,\n",
    "                                unit,\n",
    "                                status.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b475d2",
   "metadata": {},
   "source": [
    "2)이번주 로또 번호 출력\n",
    "https://dhlottery.co.kr/gameResult.do?method=byWin (google에 로또번호 당첨번호 검색)\n",
    "    1197회(2025년 11월 08일 추첨)\n",
    "    당첨번호 [1, 5, 7, 26, 28, 43]\n",
    "    보너스 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7c65a",
   "metadata": {},
   "source": [
    "## 2) 이번주 로또 번호 출력\n",
    "* https://dhlottery.co.kr/gameResult.do?method=byWin (google에 로또번호 당첨번호 검색)\n",
    "\n",
    "    1197회(2025년 11월 08일 추첨)\n",
    "    \n",
    "    당첨번호 [1, 5, 7, 26, 28, 43]\n",
    "    \n",
    "    보너스 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f066125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aad863b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "url = 'https://dhlottery.co.kr/gameResult.do?method=byWin'\n",
    "response = urlopen(url)\n",
    "response.status\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ecc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = soup.select_one('div.win_result strong').text # 1197회\n",
    "date  = soup.select_one('div.win_result > p.desc').text\n",
    "# date = soup.find('p', class_='desc').text\n",
    "lotto_number_el = soup.select('div.num.win span')\n",
    "lotto_number = [int(el.text) for el in lotto_number_el]\n",
    "bonus_number = int(soup.select_one('div.num.bonus > p > span').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c12a9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197회 (2025년 11월 08일 추첨)\n",
      "당첨번호  [1, 5, 7, 26, 28, 43]\n",
      "보 너 스  30\n"
     ]
    }
   ],
   "source": [
    "print(times, date)\n",
    "print('당첨번호 ',lotto_number)\n",
    "print('보 너 스 ', bonus_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2f375eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1d5cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최신 회차: 1197회\n",
      "\n",
      "✅ 제 1197회 로또 당첨번호\n",
      "추첨일: 2025-11-08\n",
      "번호: [1, 5, 7, 26, 28, 43]\n",
      "보너스: 30\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  # 1. import 추가\n",
    "\n",
    "def get_latest_lotto_api():\n",
    "    \"\"\"동행복권 API를 사용한 최신 로또 번호 조회 (오류 처리 포함)\"\"\"\n",
    "    try:\n",
    "        # 2. URL 공백 제거\n",
    "        main_url = 'https://dhlottery.co.kr/common.do?method=main'\n",
    "        response = requests.get(main_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # 회차 요소가 없을 경우 대비\n",
    "        round_element = soup.find('strong', id='lottoDrwNo')\n",
    "        if not round_element:\n",
    "            raise ValueError(\"회차 정보를 찾을 수 없습니다\")\n",
    "        \n",
    "        latest_round = int(round_element.text)\n",
    "        print(f\"최신 회차: {latest_round}회\")\n",
    "        \n",
    "        # 3. 도메인 통일 및 공백 제거\n",
    "        api_url = f'https://dhlottery.co.kr/common.do?method=getLottoNumber&drwNo={latest_round}'\n",
    "        api_response = requests.get(api_url, timeout=10)\n",
    "        api_response.raise_for_status()\n",
    "        \n",
    "        data = api_response.json()\n",
    "        \n",
    "        # 4. 응답 데이터 검증\n",
    "        if data.get('returnValue') == 'fail':\n",
    "            raise ValueError(f\"해당 회차({latest_round}) 데이터가 없습니다\")\n",
    "        \n",
    "        return {\n",
    "            'round': data['drwNo'],\n",
    "            'date': data['drwNoDate'],\n",
    "            'numbers': [data[f'drwtNo{i}'] for i in range(1, 7)],\n",
    "            'bonus': data['bnusNo']\n",
    "        }\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ 네트워크 오류: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 처리 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    result = get_latest_lotto_api()\n",
    "    if result:\n",
    "        print(f\"\\n✅ 제 {result['round']}회 로또 당첨번호\")\n",
    "        print(f\"추첨일: {result['date']}\")\n",
    "        print(f\"번호: {result['numbers']}\")\n",
    "        print(f\"보너스: {result['bonus']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ad771a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "이번주 로또 6/45 당첨번호\n",
      "========================================\n",
      "회차: 제 1197회\n",
      "추첨일: (2025년 11월 08일 추첨)\n",
      "당첨번호: [1, 5, 7, 26, 28, 43]\n",
      "보너스번호: 30\n",
      "\n",
      "[번호 분포]\n",
      "  1번째 숫자: 01\n",
      "  2번째 숫자: 05\n",
      "  3번째 숫자: 07\n",
      "  4번째 숫자: 26\n",
      "  5번째 숫자: 28\n",
      "  6번째 숫자: 43\n",
      "  보너스: 30\n"
     ]
    }
   ],
   "source": [
    "# 방법 1: requests (추천)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def get_latest_lotto_numbers():\n",
    "    \"\"\"\n",
    "    이번주 최신 로또 당첨번호를 가져오는 함수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. 최신 회차 번호 가져오기\n",
    "        main_url = 'https://dhlottery.co.kr/common.do?method=main'\n",
    "        response = requests.get(main_url)\n",
    "        response.raise_for_status()  # 오류 체크\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        latest_round = int(soup.find('strong', id='lottoDrwNo').text)\n",
    "        \n",
    "        # 2. 당첨 정보 페이지 접근\n",
    "        url = f'https://dhlottery.co.kr/gameResult.do?method=byWin&drwNo={latest_round}'\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # 3. 추첨일 추출\n",
    "        draw_date = soup.find('p', class_='desc').text\n",
    "        \n",
    "        # 4. 당첨번호 추출\n",
    "        win_numbers = []\n",
    "        win_area = soup.find('div', class_='num win').find_all('span')\n",
    "        for num in win_area:\n",
    "            win_numbers.append(int(num.text))\n",
    "        \n",
    "        # 5. 보너스번호 추출\n",
    "        bonus_number = int(soup.find('div', class_='num bonus').find('span').text)\n",
    "        \n",
    "        return {\n",
    "            'round': latest_round,\n",
    "            'date': draw_date,\n",
    "            'numbers': win_numbers,\n",
    "            'bonus': bonus_number\n",
    "        }\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"요청 중 오류 발생: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 처리 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# 실행 및 결과 출력\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 40)\n",
    "    print(\"이번주 로또 6/45 당첨번호\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    result = get_latest_lotto_numbers()\n",
    "    if result:\n",
    "        print(f\"회차: 제 {result['round']}회\")\n",
    "        print(f\"추첨일: {result['date']}\")\n",
    "        print(f\"당첨번호: {result['numbers']}\")\n",
    "        print(f\"보너스번호: {result['bonus']}\")\n",
    "        \n",
    "        # 시각적 표현\n",
    "        print(\"\\n[번호 분포]\")\n",
    "        for i, num in enumerate(result['numbers'], 1):\n",
    "            print(f\"  {i}번째 숫자: {num:02d}\")\n",
    "        print(f\"  보너스: {result['bonus']:02d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79d5fd",
   "metadata": {},
   "source": [
    "\n",
    "## 3) 다음 검색 리스트\n",
    "no title               link\n",
    "0  한풀 꺾인 비트코인  https://v.daum.net/v/20251110094711892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b09429d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=비트코인\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"돈 풀린다\"...비트코인, 美 셧다운 해제 기대감에 5% 급등</td>\n",
       "      <td>http://v.daum.net/v/20251110164345783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?</td>\n",
       "      <td>http://v.daum.net/v/20251110094711892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?</td>\n",
       "      <td>http://v.daum.net/v/20251110092814031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[투자 노하우] 美 셧다운 종료 기대감…비트코인 10만6천달러선</td>\n",
       "      <td>http://v.daum.net/v/20251110165508316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[자막뉴스] 올해 초까지 가장 핫했는데…\"안전띠 꽉 매세요\" 투자자 '비명'</td>\n",
       "      <td>http://v.daum.net/v/20251110165704414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"2000달러 관세 배당\" 비트코인에 불 지핀 트럼프…산타랠리 시작?</td>\n",
       "      <td>http://v.daum.net/v/20251110160448927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>“지금 들어가?”… 트럼프 관세 배당 발언에 10만달러 회복한 비트코인</td>\n",
       "      <td>http://v.daum.net/v/20251110114112103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]</td>\n",
       "      <td>http://v.daum.net/v/20251110112101913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>“비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다</td>\n",
       "      <td>http://v.daum.net/v/20251110094507791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내</td>\n",
       "      <td>http://v.daum.net/v/20251110081500340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                         title  \\\n",
       "0   0          \"돈 풀린다\"...비트코인, 美 셧다운 해제 기대감에 5% 급등    \n",
       "1   1                  \"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?    \n",
       "2   2                비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?    \n",
       "3   3          [투자 노하우] 美 셧다운 종료 기대감…비트코인 10만6천달러선    \n",
       "4   4   [자막뉴스] 올해 초까지 가장 핫했는데…\"안전띠 꽉 매세요\" 투자자 '비명'    \n",
       "5   5       \"2000달러 관세 배당\" 비트코인에 불 지핀 트럼프…산타랠리 시작?    \n",
       "6   6      “지금 들어가?”… 트럼프 관세 배당 발언에 10만달러 회복한 비트코인    \n",
       "7   7           트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]    \n",
       "8   8           “비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다    \n",
       "9   9     비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251110164345783  \n",
       "1  http://v.daum.net/v/20251110094711892  \n",
       "2  http://v.daum.net/v/20251110092814031  \n",
       "3  http://v.daum.net/v/20251110165508316  \n",
       "4  http://v.daum.net/v/20251110165704414  \n",
       "5  http://v.daum.net/v/20251110160448927  \n",
       "6  http://v.daum.net/v/20251110114112103  \n",
       "7  http://v.daum.net/v/20251110112101913  \n",
       "8  http://v.daum.net/v/20251110094507791  \n",
       "9  http://v.daum.net/v/20251110081500340  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "word = '비트코인'\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q='+word\n",
    "print(url)\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 방법2 : 불가\n",
    "# from urllib.request import urlopen\n",
    "# from urllib.parse import quote\n",
    "# word = quote('비트코인') # url에 한글이 포함된 경우 한글을 quote()로 변환\n",
    "# url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q='+word\n",
    "# print(url)\n",
    "# response = urlopen(url)\n",
    "# soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "items_find_list = [] # 검색한 결과를 담을 리스트(딕셔너리 list)\n",
    "items_el = soup.select('div.item-title > strong.tit-g > a')\n",
    "for idx, item in enumerate(items_el):\n",
    "    # print(idx, item.text, item.attrs.get('href'))\n",
    "    items_find_list.append({'no':idx,\n",
    "                           'title':item.text,\n",
    "                           'link':item.attrs.get('href')})\n",
    "import pandas as pd\n",
    "pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e6aca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>번호</th>\n",
       "      <th>제목</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"돈 풀린다\"...비트코인, 美 셧다운 해제 기대감에 5% 급등</td>\n",
       "      <td>http://v.daum.net/v/20251110164345783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?</td>\n",
       "      <td>http://v.daum.net/v/20251110094711892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?</td>\n",
       "      <td>http://v.daum.net/v/20251110092814031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[투자 노하우] 美 셧다운 종료 기대감…비트코인 10만6천달러선</td>\n",
       "      <td>http://v.daum.net/v/20251110165508316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[자막뉴스] 올해 초까지 가장 핫했는데…\"안전띠 꽉 매세요\" 투자자 '비명'</td>\n",
       "      <td>http://v.daum.net/v/20251110165704414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"2000달러 관세 배당\" 비트코인에 불 지핀 트럼프…산타랠리 시작?</td>\n",
       "      <td>http://v.daum.net/v/20251110160448927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>“지금 들어가?”… 트럼프 관세 배당 발언에 10만달러 회복한 비트코인</td>\n",
       "      <td>http://v.daum.net/v/20251110114112103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]</td>\n",
       "      <td>http://v.daum.net/v/20251110112101913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>“비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다</td>\n",
       "      <td>http://v.daum.net/v/20251110094507791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내</td>\n",
       "      <td>http://v.daum.net/v/20251110081500340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   번호                                            제목  \\\n",
       "0   0          \"돈 풀린다\"...비트코인, 美 셧다운 해제 기대감에 5% 급등    \n",
       "1   1                  \"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?    \n",
       "2   2                비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?    \n",
       "3   3          [투자 노하우] 美 셧다운 종료 기대감…비트코인 10만6천달러선    \n",
       "4   4   [자막뉴스] 올해 초까지 가장 핫했는데…\"안전띠 꽉 매세요\" 투자자 '비명'    \n",
       "5   5       \"2000달러 관세 배당\" 비트코인에 불 지핀 트럼프…산타랠리 시작?    \n",
       "6   6      “지금 들어가?”… 트럼프 관세 배당 발언에 10만달러 회복한 비트코인    \n",
       "7   7           트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]    \n",
       "8   8           “비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다    \n",
       "9   9     비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내    \n",
       "\n",
       "                                      링크  \n",
       "0  http://v.daum.net/v/20251110164345783  \n",
       "1  http://v.daum.net/v/20251110094711892  \n",
       "2  http://v.daum.net/v/20251110092814031  \n",
       "3  http://v.daum.net/v/20251110165508316  \n",
       "4  http://v.daum.net/v/20251110165704414  \n",
       "5  http://v.daum.net/v/20251110160448927  \n",
       "6  http://v.daum.net/v/20251110114112103  \n",
       "7  http://v.daum.net/v/20251110112101913  \n",
       "8  http://v.daum.net/v/20251110094507791  \n",
       "9  http://v.daum.net/v/20251110081500340  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_find_list = [] # 검색한 결과를 담을 리스트\n",
    "items_el = soup.select('div.item-title > strong.tit-g > a')\n",
    "for idx, item in enumerate(items_el):\n",
    "    items_find_list.append([idx, item.text, item.attrs['href']])\n",
    "pd.DataFrame(items_find_list, columns=['번호', '제목', '링크'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "828fca0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"돈 풀린다\"...비트코인, 美 셧다운 해제 기대감에 5% 급등</td>\n",
       "      <td>http://v.daum.net/v/20251110164345783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?</td>\n",
       "      <td>http://v.daum.net/v/20251110094711892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?</td>\n",
       "      <td>http://v.daum.net/v/20251110092814031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[투자 노하우] 美 셧다운 종료 기대감…비트코인 10만6천달러선</td>\n",
       "      <td>http://v.daum.net/v/20251110165508316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[자막뉴스] 올해 초까지 가장 핫했는데…\"안전띠 꽉 매세요\" 투자자 '비명'</td>\n",
       "      <td>http://v.daum.net/v/20251110165704414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"2000달러 관세 배당\" 비트코인에 불 지핀 트럼프…산타랠리 시작?</td>\n",
       "      <td>http://v.daum.net/v/20251110160448927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>“지금 들어가?”… 트럼프 관세 배당 발언에 10만달러 회복한 비트코인</td>\n",
       "      <td>http://v.daum.net/v/20251110114112103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]</td>\n",
       "      <td>http://v.daum.net/v/20251110112101913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>“비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다</td>\n",
       "      <td>http://v.daum.net/v/20251110094507791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내</td>\n",
       "      <td>http://v.daum.net/v/20251110081500340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                         title  \\\n",
       "0   0          \"돈 풀린다\"...비트코인, 美 셧다운 해제 기대감에 5% 급등    \n",
       "1   1                  \"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?    \n",
       "2   2                비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?    \n",
       "3   3          [투자 노하우] 美 셧다운 종료 기대감…비트코인 10만6천달러선    \n",
       "4   4   [자막뉴스] 올해 초까지 가장 핫했는데…\"안전띠 꽉 매세요\" 투자자 '비명'    \n",
       "5   5       \"2000달러 관세 배당\" 비트코인에 불 지핀 트럼프…산타랠리 시작?    \n",
       "6   6      “지금 들어가?”… 트럼프 관세 배당 발언에 10만달러 회복한 비트코인    \n",
       "7   7           트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]    \n",
       "8   8           “비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다    \n",
       "9   9     비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251110164345783  \n",
       "1  http://v.daum.net/v/20251110094711892  \n",
       "2  http://v.daum.net/v/20251110092814031  \n",
       "3  http://v.daum.net/v/20251110165508316  \n",
       "4  http://v.daum.net/v/20251110165704414  \n",
       "5  http://v.daum.net/v/20251110160448927  \n",
       "6  http://v.daum.net/v/20251110114112103  \n",
       "7  http://v.daum.net/v/20251110112101913  \n",
       "8  http://v.daum.net/v/20251110094507791  \n",
       "9  http://v.daum.net/v/20251110081500340  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_find_list = [] # 검색한 결과를 담을 리스트\n",
    "# div.item-title > strong.tit-g > a\n",
    "item_titles = soup.find_all('div', class_='item-title')\n",
    "for idx, item in enumerate(item_titles):\n",
    "    a = item.find('a')\n",
    "    #print(idx, a.text, a.attrs['href'])\n",
    "    #items_find_list.append([idx, a.text, a.attrs['href']])\n",
    "    items_find_list.append({\n",
    "        'no':idx,\n",
    "        'title':a.text,\n",
    "        'link':a.attrs['href'],\n",
    "    })\n",
    "pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04476a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?</td>\n",
       "      <td>http://v.daum.net/v/20251110094711892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?</td>\n",
       "      <td>http://v.daum.net/v/20251110092814031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"비트코인 21억 간다더니\"...갑자기 말 바꿨다</td>\n",
       "      <td>http://v.daum.net/v/20251109105545139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]</td>\n",
       "      <td>http://v.daum.net/v/20251110112101913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>비트코인, 트럼프 ‘2000달러 지급’ 발언에 10만4000달러선 [크립토브리핑]</td>\n",
       "      <td>http://v.daum.net/v/20251110103033108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>“비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다</td>\n",
       "      <td>http://v.daum.net/v/20251110094507791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>비트코인 '와르르' 내려오는데 '의외'의 전망</td>\n",
       "      <td>http://v.daum.net/v/20251107210115339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[가상자산 나침반] ‘겹악재’ 비트코인, 반전 포인트 나올까</td>\n",
       "      <td>http://v.daum.net/v/20251109112746909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>美 셧다운 종료 기대…비트코인, 10만 5000달러 회복[코인브리핑]</td>\n",
       "      <td>http://v.daum.net/v/20251110111435519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내</td>\n",
       "      <td>http://v.daum.net/v/20251110081500340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                            title  \\\n",
       "0   0                     \"한풀 꺾인 비트코인, 상승세 곧 회복\"…근거는?    \n",
       "1   1                   비트코인 1억5500만원대 소폭 상승…트럼프 발언탓?    \n",
       "2   2                     \"비트코인 21억 간다더니\"...갑자기 말 바꿨다    \n",
       "3   3              트럼프 돈 푼다...비트코인, 관세 배당금에 반등 [매일코인]    \n",
       "4   4   비트코인, 트럼프 ‘2000달러 지급’ 발언에 10만4000달러선 [크립토브리핑]    \n",
       "5   5              “비트코인 약세, 닷컴버블과 판박이”…큰손·장투족 매일 던진다    \n",
       "6   6                       비트코인 '와르르' 내려오는데 '의외'의 전망    \n",
       "7   7               [가상자산 나침반] ‘겹악재’ 비트코인, 반전 포인트 나올까    \n",
       "8   8          美 셧다운 종료 기대…비트코인, 10만 5000달러 회복[코인브리핑]    \n",
       "9   9        비트플래닛, 비트코인 200개 매입 완료…자금 조달부터 커스터디까지 끝내    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251110094711892  \n",
       "1  http://v.daum.net/v/20251110092814031  \n",
       "2  http://v.daum.net/v/20251109105545139  \n",
       "3  http://v.daum.net/v/20251110112101913  \n",
       "4  http://v.daum.net/v/20251110103033108  \n",
       "5  http://v.daum.net/v/20251110094507791  \n",
       "6  http://v.daum.net/v/20251107210115339  \n",
       "7  http://v.daum.net/v/20251109112746909  \n",
       "8  http://v.daum.net/v/20251110111435519  \n",
       "9  http://v.daum.net/v/20251110081500340  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_find_list = [] # 검색한 결과를 담을 리스트\n",
    "# div.item-title > strong.tit-g > a\n",
    "item_titles = soup.find_all('div', class_='item-title')\n",
    "for idx, item in enumerate(item_titles):\n",
    "    a = item.find('a')\n",
    "    #print(idx, a.text, a.attrs['href'])\n",
    "    #items_find_list.append([idx, a.text, a.attrs['href']])\n",
    "    items_find_list.append({\n",
    "        'no':idx,\n",
    "        'title':a.text,\n",
    "        'link':a.attrs['href'],\n",
    "    })\n",
    "pd.DataFrame(items_find_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af868351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 뉴스 검색(원하는 키워드를 원하는 페이지를 가져오기)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "def collect_news_list(keyword, page):\n",
    "    'keyword로 page에 다음 뉴스검색한 결과를 출력->list를 return'\n",
    "    url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q={keyword}&p={page}'\n",
    "    response = requests.get(url)\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69f9b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): search.daum.net:443\n",
      "DEBUG:urllib3.connectionpool:https://search.daum.net:443 \"GET /search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q=%EC%B2%AD%EB%B0%94%EC%A7%80&p=2 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "collect_news_list('청바지', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904c9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 뉴스 검색(원하는 키워드를 원하는 페이지를 가져오기)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "def collect_news_list(keyword, page):\n",
    "    'keyword로 page에 다음 뉴스검색한 결과를 출력->list를 return'\n",
    "    #url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q={keyword}&p={page}'\n",
    "    # response = requests.get(url)\n",
    "    url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8'\n",
    "    params = {'q':keyword, 'p':page}\n",
    "    response = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    items_find_list = [] # 검색한 결과를 담는 리스트\n",
    "    item_titles = soup.select('div.item-title > strong.tit-g > a')\n",
    "    print(keyword)\n",
    "    for idx, item in enumerate(item_titles):\n",
    "        print([(page-1)*10+idx, item.text, item.attrs['href']])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79f157eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): search.daum.net:443\n",
      "DEBUG:urllib3.connectionpool:https://search.daum.net:443 \"GET /search?w=news&nil_search=btn&DA=PGD&enc=utf8&q=%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8&p=3 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비트코인\n",
      "[20, ' 비트코인, 위태로운 10만 달러...\"하락장 전환\"vs\"숨고르기\" ', 'http://v.daum.net/v/20251106140714590']\n",
      "[21, ' 연구소서 실험하려 샀는데…비트코인 1000배 대박 터졌다 ', 'http://v.daum.net/v/20251109120511705']\n",
      "[22, ' \"비트코인 \\'1000배 잭팟\\' 터뜨렸어요\"···실험용으로 97개 샀다가 \\'횡재\\' 맞은 \\'이 나라\\' ', 'http://v.daum.net/v/20251109075014647']\n",
      "[23, ' 돈나무 언니도 생각 바꿨다…비트코인 강세전망 20%↓ ', 'http://v.daum.net/v/20251107040000760']\n",
      "[24, ' JP모건 \"비트코인, 금 비해 저평가...공정가치 17만 달러\" ', 'http://v.daum.net/v/20251107092549359']\n",
      "[25, ' 돈나무 언니, 비트코인 전망 120만달러로 낮췄다...왜? ', 'http://v.daum.net/v/20251107170008576']\n",
      "[26, \" 연구용으로 산 비트코인 97개…13년만에 1000배 수익 '잭팟' \", 'http://v.daum.net/v/20251109113613079']\n",
      "[27, ' “주식보다 더 떨어져”…휘청이는 비트코인 “분위기 반전 어렵다” ', 'http://v.daum.net/v/20251106171049044']\n",
      "[28, ' 한때 10만弗 붕괴, 날개 꺾인 비트코인 ', 'http://v.daum.net/v/20251106041647056']\n",
      "[29, ' “곡소리 들리네” 비트코인·이더리움 붕괴…위험자산 ‘회피 심리’ ', 'http://v.daum.net/v/20251105080314455']\n"
     ]
    }
   ],
   "source": [
    "collect_news_list('비트코인', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0b5809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 뉴스 검색(원하는 키워드를 원하는 페이지를 가져오기)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "def collect_news_list(keyword, page):\n",
    "    'keyword로 page에 다음 뉴스검색한 결과를 출력->list를 return'\n",
    "    #url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&cluster=y&cluster_page=1&q={keyword}&p={page}'\n",
    "    # response = requests.get(url)\n",
    "    url = f'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8'\n",
    "    params = {'q':keyword, 'p':page}\n",
    "    response = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    items_find_list = [] # 검색한 결과를 담는 리스트\n",
    "    item_titles = soup.select('div.item-title > strong.tit-g > a')\n",
    "    for idx, item in enumerate(item_titles):\n",
    "        items_find_list.append([(page-1)*10+idx, item.text, item.attrs['href']])\n",
    "    return items_find_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dddbd4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  \" 초중고 정보 교과 내 AI 교육 확대…모든 교육청 'AI 지원센터' 설립 \",\n",
       "  'http://v.daum.net/v/20251110140139274'],\n",
       " [1,\n",
       "  ' 또 퍼지는 ‘AI거품론’… 커지는 ‘AI워싱’ 경보 ',\n",
       "  'http://v.daum.net/v/20251109183027380'],\n",
       " [2, ' AI 거품론 속…오픈AI, 백악관에 SOS ', 'http://v.daum.net/v/20251110042102550'],\n",
       " [3,\n",
       "  \" 무협, 'AI 서밋 서울 2025' 개막…글로벌 AI 기업 총집결 \",\n",
       "  'http://v.daum.net/v/20251110164225706'],\n",
       " [4,\n",
       "  \" [뉴스1 PICK]국내 최대 AI 컨펙스 'AI 서밋 서울 & 엑스포' 개막 \",\n",
       "  'http://v.daum.net/v/20251110145713498'],\n",
       " [5,\n",
       "  ' 5.5년만에 AI 박사학위 취득...내년 AI인재양성에 1.4조 예산 투입 ',\n",
       "  'http://v.daum.net/v/20251110142138252'],\n",
       " [6,\n",
       "  ' 서울AI재단-MIT 센서블시티랩, 도시 AI 연구 협력 본격화 ',\n",
       "  'http://v.daum.net/v/20251110173813202'],\n",
       " [7,\n",
       "  ' \"도메인 지식 없는 AI는 공허\"···최태원, 본업 기반 AI 경쟁력 강조 ',\n",
       "  'http://v.daum.net/v/20251110144852927'],\n",
       " [8,\n",
       "  ' 야놀자, 첫 AI 해커톤 개최…\"AI 혁신 전사적 전파할 것\" ',\n",
       "  'http://v.daum.net/v/20251110160146766'],\n",
       " [9,\n",
       "  \" 중견회계법인협의회, AI 감사 솔루션 '오딘 AI' 도입 \",\n",
       "  'http://v.daum.net/v/20251110150515967']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_news_list('AI', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9128d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===1번째 검색어 청바지 검색 결과 수집 중입니다===\n",
      "===2번째 검색어 동대문 검색 결과 수집 중입니다===\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "keywords = ['청바지', '동대문']\n",
    "result0 = [] # 청바지 1~3페이지까지 검색한 결과를 담을 list\n",
    "result1 = [] # 동대문 1~3페이지까지 검색한 결과를 담을 list\n",
    "pages = 3\n",
    "for i, keyword in enumerate(keywords):\n",
    "    print(f'==={i+1}번째 검색어 {keyword} 검색 결과 수집 중입니다===')\n",
    "    for page in range(1, pages+1):\n",
    "        if i==0:\n",
    "            result0.extend(collect_news_list(keyword, page))\n",
    "        elif i==1:\n",
    "            result1.extend(collect_news_list(keyword, page))\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82056eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>“돈 벌어가세요” 동대문 일요시장, 겨울옷 핫플된 사연? [르포]</td>\n",
       "      <td>http://v.daum.net/v/20251110100357735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>동대문구, ‘11월 자전거교실’ 개강… 올해 마지막 초보자 교육 진행</td>\n",
       "      <td>http://v.daum.net/v/20251110145114101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>음주운전 차, 동대문역서 인도 돌진...日 관광객 '사망'</td>\n",
       "      <td>http://v.daum.net/v/20251103073316480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>동대문구, 25일까지 '주민 건강도시학교'···\"건강하게 살자\"</td>\n",
       "      <td>http://v.daum.net/v/20251109223318356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>서울 동대문구, 15일 배봉산정원 가족축제 개최</td>\n",
       "      <td>http://v.daum.net/v/20251104104517122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                     title  \\\n",
       "0   0     “돈 벌어가세요” 동대문 일요시장, 겨울옷 핫플된 사연? [르포]    \n",
       "1   1   동대문구, ‘11월 자전거교실’ 개강… 올해 마지막 초보자 교육 진행    \n",
       "2   2         음주운전 차, 동대문역서 인도 돌진...日 관광객 '사망'    \n",
       "3   3      동대문구, 25일까지 '주민 건강도시학교'···\"건강하게 살자\"    \n",
       "4   4               서울 동대문구, 15일 배봉산정원 가족축제 개최    \n",
       "\n",
       "                                    link  \n",
       "0  http://v.daum.net/v/20251110100357735  \n",
       "1  http://v.daum.net/v/20251110145114101  \n",
       "2  http://v.daum.net/v/20251103073316480  \n",
       "3  http://v.daum.net/v/20251109223318356  \n",
       "4  http://v.daum.net/v/20251104104517122  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0_df = pd.DataFrame(result0, columns=['no', 'title','link'])\n",
    "result1_df = pd.DataFrame(result1, columns=['no', 'title','link'])\n",
    "result1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3351f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result0_df.to_csv(f'data/ch14_{keywords[0]}.csv', index=False, encoding='cp949')\n",
    "result1_df.to_csv(f'data/ch14_{keywords[1]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c37d39",
   "metadata": {},
   "source": [
    "### 4) User-Agent를 추가하여 크롤링\n",
    "* 자동으로 브라우저를 통해 요청하는 것처럼 보이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c2a2eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&q=%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8\n"
     ]
    }
   ],
   "source": [
    "# 방법 2:\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import quote\n",
    "word=quote('비트코인')\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&q='+word\n",
    "print(url)\n",
    "headers={ 'User-Agent':\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36'}\n",
    "request=Request(url,headers=headers)\n",
    "response=urlopen(request)\n",
    "soup=BeautifulSoup(response, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2d4c2",
   "metadata": {},
   "source": [
    "* https://www.melon.com/chart/index.htm\n",
    "\n",
    "* https://wwww.melon.com/robots.txt 에서 User-Agent에 봇이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcb298ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&q=%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8\n"
     ]
    }
   ],
   "source": [
    "# 방법2 : \n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import quote\n",
    "word = quote('비트코인') # 한글을 encoding 처리\n",
    "url = 'https://search.daum.net/search?w=news&nil_search=btn&DA=PGD&enc=utf8&q='+word\n",
    "print(url)\n",
    "# headers = {'User-Agent':\n",
    "#           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "# request = Request(url, headers=headers)\n",
    "request = Request(url)\n",
    "request.add_header('User-Agent', \n",
    "                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36')\n",
    "\n",
    "response = urlopen(request)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861a6d0",
   "metadata": {},
   "source": [
    "* https://www.melon.com/chart/index.htm\n",
    "* https://wwww.melon.com/robots.txt 에서 User-Agent에 봇이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "545801fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [406]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "url = 'https://www.melon.com/chart/index.htm'\n",
    "melonpage = requests.get(url)\n",
    "melonpage\n",
    "# soup = BeautifulSoup(melonpage.text, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ccbe881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2 : User-Agent 추가\n",
    "from urllib.request import urlopen, Request\n",
    "url = 'https://www.melon.com/chart/index.htm'\n",
    "# melonpage = urlopen(url) # 에러남\n",
    "headers = {'user-agent':\n",
    "          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "request = Request(url, headers=headers)\n",
    "melonpage = urlopen(request)\n",
    "soup = BeautifulSoup(melonpage, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a017350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1위 | Blue Valentine - NMIXXNMIXX\n",
      "2위 | 타임캡슐 - 다비치다비치\n",
      "3위 | Golden - HUNTR/X, EJAE, AUDRE\n",
      "4위 | Drowning - WOODZWOODZ\n",
      "5위 | Good Goodbye - 화사 (HWASA)화사 (HWASA)\n",
      "6위 | SPAGHETTI (feat. j-hope of BTS) - LE SSERAFIM (르세라핌), \n",
      "7위 | 달리 표현할 수 없어요 - 로이킴로이킴\n",
      "8위 | 뛰어(JUMP) - BLACKPINKBLACKPINK\n",
      "9위 | Soda Pop - KPop Demon Hunters C\n",
      "10위 | 어제보다 슬픈 오늘 - 우디 (Woody)우디 (Woody)\n",
      "11위 | 시작의 아이 ❍ - 박다혜, 마크툽 (MAKTUB)박다혜\n",
      "12위 | FAMOUS - ALLDAY PROJECTALLDAY\n",
      "13위 | IRIS OUT - Kenshi YonezuKenshi \n",
      "14위 | 모르시나요(PROD.로코베리) - 조째즈조째즈\n",
      "15위 | XOXZ - IVE (아이브)IVE (아이브)\n",
      "16위 | Rich Man - aespaaespa\n",
      "17위 | 한번 더 이별 - 이창섭이창섭\n",
      "18위 | Hollywood Action - BOYNEXTDOORBOYNEXTDO\n",
      "19위 | 너에게 닿기를 - 10CM10CM\n",
      "20위 | 내게 사랑이 뭐냐고 물어본다면 - 로이킴로이킴\n",
      "21위 | HOME SWEET HOME (feat. 태양, 대성) - G-DRAGONG-DRAGON\n",
      "22위 | 운명 (2025) - 먼데이 키즈, 이이경먼데이 키즈, 이\n",
      "23위 | body - 다영 (DAYOUNG)다영 (DAYO\n",
      "24위 | Whiplash - aespaaespa\n",
      "25위 | toxic till the end - 로제 (ROSÉ)로제 (ROSÉ)\n",
      "26위 | 시작의 아이 - 마크툽 (MAKTUB)마크툽 (MAK\n",
      "27위 | 천상연 - 이창섭이창섭\n",
      "28위 | 어떻게 이별까지 사랑하겠어, 널 사랑하는 거지 - AKMU (악뮤)AKMU (악뮤)\n",
      "29위 | 나는 반딧불 - 황가람황가람\n",
      "30위 | 청춘만화 - 이무진이무진\n",
      "31위 | HAPPY - DAY6 (데이식스)DAY6 (데이식\n",
      "32위 | like JENNIE - 제니 (JENNIE)제니 (JENNI\n",
      "33위 | 오늘만 I LOVE YOU - BOYNEXTDOORBOYNEXTDO\n",
      "34위 | FOCUS - Hearts2Hearts (하츠투하츠\n",
      "35위 | APT. - 로제 (ROSÉ), Bruno Mar\n",
      "36위 | 멸종위기사랑 - 이찬혁이찬혁\n",
      "37위 | Never Ending Story - 아이유아이유\n",
      "38위 | 한 페이지가 될 수 있게 - DAY6 (데이식스)DAY6 (데이식\n",
      "39위 | Dirty Work - aespaaespa\n",
      "40위 | 소나기 - 이클립스 (ECLIPSE)이클립스 (\n",
      "41위 | Flower - 오반(OVAN)오반(OVAN)\n",
      "42위 | Your Idol - KPop Demon Hunters C\n",
      "43위 | 그대만 있다면 (여름날 우리 X 너드커넥션 (Nerd Connection)) - 너드커넥션 (Nerd Connecti\n",
      "44위 | 사랑하게 될 거야 - 한로로한로로\n",
      "45위 | 예뻤어 - DAY6 (데이식스)DAY6 (데이식\n",
      "46위 | Welcome to the Show - DAY6 (데이식스)DAY6 (데이식\n",
      "47위 | STYLE - Hearts2Hearts (하츠투하츠\n",
      "48위 | 너의 모든 순간 - 성시경성시경\n",
      "49위 | 주저하는 연인들을 위해 - 잔나비잔나비\n",
      "50위 | 모든 날, 모든 순간 (Every day, Every Moment) - 폴킴폴킴\n",
      "51위 | 가만히 눈을 감고 - DK(디셈버)DK(디셈버)\n",
      "52위 | 사랑은 늘 도망가 - 임영웅임영웅\n",
      "53위 | Die With A Smile - Lady Gaga, Bruno Mar\n",
      "54위 | REBEL HEART - IVE (아이브)IVE (아이브)\n",
      "55위 | TOO BAD (feat. Anderson .Paak) - G-DRAGONG-DRAGON\n",
      "56위 | Love wins all - 아이유아이유\n",
      "57위 | 빌려온 고양이 (Do the Dance) - 아일릿(ILLIT)아일릿(ILLIT)\n",
      "58위 | 첫 만남은 계획대로 되지 않아 - TWS (투어스)TWS (투어스)\n",
      "59위 | 청혼하지 않을 이유를 못 찾았어 - 이무진이무진\n",
      "60위 | 다정히 내 이름을 부르면 - 경서예지, 전건호경서예지, 전건호\n",
      "61위 | 바이, 썸머 - 아이유아이유\n",
      "62위 | MY LOVE(2025) - 이예은, 아샤트리, 전건호이예은, 아\n",
      "63위 | 사랑인가 봐 - 멜로망스멜로망스\n",
      "64위 | 헤어지자 말해요 - 박재정박재정\n",
      "65위 | 인사 - 범진범진\n",
      "66위 | Supernova - aespaaespa\n",
      "67위 | WICKED - ALLDAY PROJECTALLDAY\n",
      "68위 | I AM - IVE (아이브)IVE (아이브)\n",
      "69위 | Magnetic - 아일릿(ILLIT)아일릿(ILLIT)\n",
      "70위 | 순간을 영원처럼 - 임영웅임영웅\n",
      "71위 | JANE DOE - Kenshi Yonezu, Hikar\n",
      "72위 | 슬픈 초대장 - 순순희(지환)순순희(지환)\n",
      "73위 | 비의 랩소디 - 임재현임재현\n",
      "74위 | 에피소드 - 이무진이무진\n",
      "75위 | OVERDRIVE - TWS (투어스)TWS (투어스)\n",
      "76위 | DRIP - BABYMONSTERBABYMONST\n",
      "77위 | Hype Boy - NewJeansNewJeans\n",
      "78위 | 고민중독 - QWERQWER\n",
      "79위 | Seven (feat. Latto) - Clean Ver. - 정국정국\n",
      "80위 | 내 이름 맑음 - QWERQWER\n",
      "81위 | HOT - LE SSERAFIM (르세라핌)LE\n",
      "82위 | PO￦ER - G-DRAGONG-DRAGON\n",
      "83위 | HANDS UP - MEOVV (미야오)MEOVV (미야\n",
      "84위 | 우리들의 블루스 - 임영웅임영웅\n",
      "85위 | 다시 만날 수 있을까 - 임영웅임영웅\n",
      "86위 | 꿈의 버스 - DAY6 (데이식스)DAY6 (데이식\n",
      "87위 | How Sweet - NewJeansNewJeans\n",
      "88위 | 숲 - 최유리최유리\n",
      "89위 | How It’s Done - HUNTR/X, EJAE, AUDRE\n",
      "90위 | 나는 아픈 건 딱 질색이니까 - i-dle (아이들)i-dle (아이\n",
      "91위 | 눈물참기 - QWERQWER\n",
      "92위 | 들꽃이 될게요 - 임영웅임영웅\n",
      "93위 | LIKE YOU BETTER - 프로미스나인프로미스나인\n",
      "94위 | 그댈 위한 멜로디 - 임영웅임영웅\n",
      "95위 | ATTITUDE - IVE (아이브)IVE (아이브)\n",
      "96위 | 천국보다 아름다운 - 임영웅임영웅\n",
      "97위 | Supersonic - 프로미스나인프로미스나인\n",
      "98위 | 비가 와서 - 임영웅임영웅\n",
      "99위 | 답장을 보낸지 - 임영웅임영웅\n",
      "100위 | 나였으면 - 나윤권, 도경수(D.O.)나윤권, 도\n"
     ]
    }
   ],
   "source": [
    "# 방법1 : User-Agent 추가\n",
    "url = 'https://www.melon.com/chart/index.htm'\n",
    "headers = {'user-agent':\n",
    "          'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'}\n",
    "melonpage = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(melonpage.text, # melonpage.content\n",
    "                    'html.parser')\n",
    "\n",
    "ranks = soup.select('td div.wrap.t_center > span.rank')\n",
    "titles = soup.select('div.ellipsis.rank01 > span') # title.text.strip()\n",
    "singers = soup.select('div.ellipsis.rank02') # singer.text.strip()[:20]\n",
    "# 1위 | 노래제목 - 가수명\n",
    "for rank, title, singer in zip(ranks, titles, singers):\n",
    "    print(f'{rank.text}위 | {title.text.strip()} - {singer.text.strip()[:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca74d4a",
   "metadata": {},
   "source": [
    "### 5) 네이버 지식인으로 검색(open API 사용x)\n",
    "- 특정 keyword를 특정 페이지 수만큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f14ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 방법1\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "keyword = '쳇지피티'\n",
    "url = f'https://kin.naver.com/search/list.naver'\n",
    "params = {'query' : keyword}\n",
    "response = get(url, params=params)\n",
    "print(response.status_code)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a8735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kin.naver.com/search/list.naver?query=%EC%B3%87%EC%A7%80%ED%94%BC%ED%8B%B0\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# 방법2\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "keyword = quote('쳇지피티')\n",
    "url = f'https://kin.naver.com/search/list.naver?query={keyword}'\n",
    "print(url)\n",
    "response = urlopen(url)\n",
    "print(response.status)\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059ed671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# 페이징 포함\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "keyword = quote('쳇지피티')\n",
    "pages = 3\n",
    "items_list = []\n",
    "for page in range(1, pages+1):\n",
    "    url=f'https://kin.naver.com/search/list.naver?query={keyword}&page={page}'\n",
    "    respons=urlopen(url)\n",
    "    # print(respons.status)\n",
    "    soup=BeautifulSoup(respons,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d20455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 페이징 포함\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "keyword = quote('쳇지피티')\n",
    "pages = 3\n",
    "items_list = [] # 크롤링한 데이터를 담을 list(title, link)\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://kin.naver.com/search/list.naver?query={keyword}&page={page}'\n",
    "    response = urlopen(url)\n",
    "    # print(response.status)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    items = soup.select('dt > a')\n",
    "    for item in items:\n",
    "        title = item.text\n",
    "        link  = item.attrs.get('href')\n",
    "        items_list.append({\n",
    "            'title': title,\n",
    "            'link' : link\n",
    "        })\n",
    "df = pd.DataFrame(items_list)\n",
    "print(df.shape)\n",
    "df.sample()\n",
    "(30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3da7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "title\tlink\n",
    "29\t쳇지피티 일러스트\thttps://kin.naver.com/qna/detail.naver?d1id=3&.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b04cf",
   "metadata": {},
   "source": [
    "## 2.2 openAPI사용: json 웹데이터 수집\n",
    "### 1) 네이버 지식인으로 검색(openAPI 사용)\n",
    "- 네이버 개발자센터에서 애플리케이션등록(이름/검색/web설정 http://localhost\n",
    "- .env 파일에 CLIENT_ID=KY_SuI6XpQ0cL7wz146v, CLIENT_SECRET=olGRlm4BqP, 환경변수 저장\n",
    "- 환경변수를 읽기 위해서 `pip install dotenv'\n",
    "_ 특정 keyword를 지식 검색(데이터수 30개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7c7974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440959a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 읽어오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\n",
    "    #dotenv_path='.env'\n",
    "        ) # 현 소스와\n",
    "# print(os.getenv('CLIENT_ID'))\n",
    "# print(os.getenv('CLIENT_SECRET'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "460839f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\n",
      "\t\"lastBuildDate\":\"Tue, 11 Nov 2025 12:03:10 +090\n"
     ]
    }
   ],
   "source": [
    "# 방법2\n",
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "encText = urllib.parse.quote(\"쳇지피티\")\n",
    "url = \"https://openapi.naver.com/v1/search/kin?query=\" + encText # JSON 결과\n",
    "# request = urllib.request.Request(url)\n",
    "# request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "# request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "headers = {\n",
    "    'X-Naver-Client-Id':client_id,\n",
    "    'X-Naver-Client-Secret':client_secret\n",
    "}\n",
    "request = urllib.request.Request(url, headers=headers)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.status\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    print(type(response_body.decode('utf-8')))\n",
    "    print(response_body.decode('utf-8')[:50])\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fcec513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"lastBuildDate\":\"Tue, 11 Nov 2025 11:23:54 +0900\",\n",
      "\t\"total\":3143,\n",
      "\t\"start\":1,\n",
      "\t\"display\":10,\n",
      "\t\"items\":[\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"<b>쳇지피티<\\/b> 사주 정확성\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=3&dirId=31501&docId=489876742&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"<b>쳇지피티<\\/b> 사주 정확성 몇프로 정도 될까요? 큰틀은 얼추 맞는거 같기도하고 모르겠네요 안녕하세요. 요즘 지피티에 대해 물어보시는 분들이 많아서 저도 해봤지만 아직 생년월일도ㅠ파악하지 못합니다. 유료버전 무료버전 둘 다... \"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"<b>쳇지피티<\\/b> 관해서\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=1&dirId=10704&docId=488200030&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"<b>쳇지피티<\\/b>한테 질문 제대로 하려면 어떻게 해야 하냐요?... <b>쳇지피티<\\/b> 한테 하는질문도 1.우리 이야기 만들래)?(호칭.... <b>쳇지피티<\\/b> 한테 어떻게 질문해야 정확한 답변을 들을수 있죠 <b>쳇지피티<\\/b> 앱이 편하시다 하신분들은 편하신이유... \"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"사주에서 뭐가 부족한지 봐주세요(<b>쳇지피티<\\/b> 답변 금지)\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=3&dirId=31501&docId=488905210&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"사주에서 뭐가 부족한지 봐주세요(<b>쳇지피티<\\/b> 답변 금지) 남매입니다 남자 1986년 9월 8일 양력 오후 5시 여자 1992년 10월 31일 양력 오전 10시 남매이고 둘다 뭐가 부족한지 봐주세요 가는곳마다 얘기가 달라서요 남자는 수와... \"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"<b>쳇지피티<\\/b> 유료로 전환시\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=1&dirId=104&docId=489089553&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"<b>쳇지피티<\\/b> 무료버전으로 카톡대화창 전송해서 상대의심리에 관한 분석요청을 많이했는데 첨부용량초과로 유료로 업그레이드하라고 뜨더라구요 업그레이드를하면 기존 무료버전대화에선 상대심리나 성격을 다... \"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"<b>쳇지피티<\\/b> 3일 리셋\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=8&dirId=8020604&docId=485726567&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"... <b>쳇지피티<\\/b> 어떻게 하는건가욤 유료결제인가요 유료결제는 얼마인가요 그거 하게되면 3일뒤에는 리셋된다고... 챗지피티 공유 업체 4인 공유 1개월 11,500원 쉐어굿에서 이용해 보세요! ▼▼ 하단에 카카오톡 채널 링크 클릭▼\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"<b>쳇지피티<\\/b> 구글계정 목록\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=1&dirId=1060305&docId=486503185&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"작년에 친구가 제 아이패드로 <b>쳇지피티<\\/b> 사이트에 들어가서 본인 아이디로 로그인을 했는데요. <b>쳇지피티<\\/b>에 들어가서... 그래서 그런지 구글 사이트에 들어가면 그 친구의 계정이 뜨지 않는데, 이상하게 <b>쳇지피티<\\/b> 사이트에 들어가서... \"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"<b>쳇지피티<\\/b> 문법\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=11&dirId=11080302&docId=488749083&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"이게 맞나요? 원래 decided to try 할때 to try가 to부정사 아닌가요..? -------------- 맞습니다. decided to try에서 to try는 'to부정사 + 동사원형'이며 decided to try~는 '“~하기로 결정했다'는 의미입니다.\"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"고등학교 수행평가에 <b>쳇지피티<\\/b> 쓰면 안되나요?\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=11&dirId=1112&docId=489851413&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"... <b>쳇지피티<\\/b>로 쓰던데 쓰면 안되아요? 요즘 지피티 검사기도 있고 선생님들도 지피티쓴 글은 다 알아보는 눈치라서요.... 답을 지피티가 써준걸 보고 쓴다면 선생님들이 지피티인거 알고 생기부나 점수를 조금 안 좋게 줄까봐 걱정돼요... \"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"<b>쳇지피티<\\/b> 이혼수 있데요\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=3&dirId=31501&docId=486992840&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"... <b>쳇지피티<\\/b>에 사주풀이 했더니 이혼수 강력 하데요... 질문자님께서는 최근 AI인 챗지피티가 이혼 사유가 될 수... 실제로 AI와의 소통, 혹은 챗지피티와의 대화가 혼인... 챗지피티 사용이 이혼 사유가 될 수 있을까? ① 일반적으로... \"\n",
      "\t\t},\n",
      "\t\t{\n",
      "\t\t\t\"title\":\"제가 직접 쓴 자소서 <b>쳇지피티<\\/b>\",\n",
      "\t\t\t\"link\":\"https:\\/\\/kin.naver.com\\/qna\\/detail.naver?d1id=4&dirId=406&docId=478038913&qb=7LOH7KeA7ZS87Yuw&enc=utf8\",\n",
      "\t\t\t\"description\":\"제가 직접 제 이야기로 자소서를 쓰고 <b>쳇지피티<\\/b>한테 보내고 지피티가 수정해준 내용 참고용으로 보고, 괜찮은 부분은... <b>쳇지피티<\\/b> 돌리면..... 제가 쓴 문맥이 그대로인 부분도 있어서 그냥 복붙하게 되는 항목도 생기는데ㅠ <b>쳇지피티<\\/b>... \"\n",
      "\t\t}\n",
      "\t]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 방법 2\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "encText = urllib.parse.quote(\"쳇지피티\")\n",
    "url = \"https://openapi.naver.com/v1/search/kin.json?query=\" + encText # JSON 결과\n",
    "# url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # XML 결과\n",
    "# request = urllib.request.Request(url)\n",
    "# request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "# request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "headers={\n",
    "    X-Naver-Client-Id\",client_id,\n",
    "    X-Naver-Client-Secret\",client_secret\n",
    "}\n",
    "request=urllib.request.Reqe\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    print\n",
    "    print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e70d05e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>쳇지피티 사주 정확성</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "      <td>쳇지피티 사주 정확성 몇프로 정도 될까요? 큰틀은 얼추 맞는거 같기도하고 모르겠네요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쳇지피티 관해서</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>쳇지피티한테 질문 제대로 하려면 어떻게 해야 하냐요?... 쳇지피티 한테 하는질문도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지)</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=3&amp;...</td>\n",
       "      <td>사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지) 남매입니다 남자 1986년 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>쳇지피티 유료로 전환시</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=1&amp;...</td>\n",
       "      <td>쳇지피티 무료버전으로 카톡대화창 전송해서 상대의심리에 관한 분석요청을 많이했는데 첨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쳇지피티 3일 리셋</td>\n",
       "      <td>https://kin.naver.com/qna/detail.naver?d1id=8&amp;...</td>\n",
       "      <td>... 쳇지피티 어떻게 하는건가욤 유료결제인가요 유료결제는 얼마인가요 그거 하게되면...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0                    쳇지피티 사주 정확성   \n",
       "1                       쳇지피티 관해서   \n",
       "2  사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지)   \n",
       "3                   쳇지피티 유료로 전환시   \n",
       "4                     쳇지피티 3일 리셋   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://kin.naver.com/qna/detail.naver?d1id=3&...   \n",
       "1  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "2  https://kin.naver.com/qna/detail.naver?d1id=3&...   \n",
       "3  https://kin.naver.com/qna/detail.naver?d1id=1&...   \n",
       "4  https://kin.naver.com/qna/detail.naver?d1id=8&...   \n",
       "\n",
       "                                         description  \n",
       "0  쳇지피티 사주 정확성 몇프로 정도 될까요? 큰틀은 얼추 맞는거 같기도하고 모르겠네요...  \n",
       "1  쳇지피티한테 질문 제대로 하려면 어떻게 해야 하냐요?... 쳇지피티 한테 하는질문도...  \n",
       "2  사주에서 뭐가 부족한지 봐주세요(쳇지피티 답변 금지) 남매입니다 남자 1986년 9...  \n",
       "3  쳇지피티 무료버전으로 카톡대화창 전송해서 상대의심리에 관한 분석요청을 많이했는데 첨...  \n",
       "4  ... 쳇지피티 어떻게 하는건가욤 유료결제인가요 유료결제는 얼마인가요 그거 하게되면...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json # response텍스트를 json스타일의 딕셔너리로\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "query = '쳇지피티'\n",
    "headers = {\n",
    "    'X-Naver-Client-Id':client_id,\n",
    "    'X-Naver-Client-Secret':client_secret\n",
    "}\n",
    "# url = f'https://openapi.naver.com/v1/search/kin?query={query}&display=30'\n",
    "# response = requests.get(url, headers=headers)\n",
    "url = 'https://openapi.naver.com/v1/search/kin'\n",
    "params = {'query':query, 'display':30}\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "# print(response.text[:500])\n",
    "# items = json.loads(response.text)['items']\n",
    "items = response.json()['items']\n",
    "items_list = []\n",
    "for item in items:\n",
    "    title = item['title'].replace('<b>','').replace('</b>','')\n",
    "    link  = item.get('link')\n",
    "    description = item.get('description').replace('<b>','').replace('</b>','')\n",
    "    items_list.append([title, link, description])\n",
    "pd.DataFrame(items_list, columns=['title', 'link', 'description']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a413b",
   "metadata": {},
   "source": [
    "### quiz) 네이버 open API를 이용해서 청바지 이미지 100건의 데이터를 ch14_청바지_csv 출력\n",
    "```\n",
    "제목, 링크, 썸네일, sizeheight, sizewidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dd1f287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 성공! 100건의 청바지 이미지 데이터를 'ch14_청바지.csv'로 저장했습니다.\n",
      "                                                  제목  \\\n",
      "0  여성 하이웨이스트 연청 와이드 청바지 통바지 편안함 스타일리시 캐주얼 데님 : 믿음...   \n",
      "1                    -30 여자 청바지 여성 데님 밴딩 일자 통 와이드 팬츠   \n",
      "2                        키작녀청바지 세미와이드청바지 진청바지 : 미니팬츠   \n",
      "\n",
      "                                                  링크  \\\n",
      "0  https://shop-phinf.pstatic.net/20251015_281/17...   \n",
      "1  http://shopping.phinf.naver.net/main_5666884/5...   \n",
      "2  http://shop1.phinf.naver.net/20240320_292/1710...   \n",
      "\n",
      "                                                 썸네일 sizeheight sizewidth  \n",
      "0  https://search.pstatic.net/common/?type=b150&s...       1000      1000  \n",
      "1  https://search.pstatic.net/common/?type=b150&s...        600       600  \n",
      "2  https://search.pstatic.net/common/?type=b150&s...       1000      1000  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. 인증 정보 설정 (환경변수에서 가져오기)\n",
    "client_id = os.getenv('CLIENT_ID')\n",
    "client_secret = os.getenv('CLIENT_SECRET')\n",
    "\n",
    "# 2. 검색어 및 API 파라미터 설정\n",
    "query = '청바지'\n",
    "url = 'https://openapi.naver.com/v1/search/image'\n",
    "headers = {\n",
    "    'X-Naver-Client-Id': client_id,\n",
    "    'X-Naver-Client-Secret': client_secret\n",
    "}\n",
    "params = {\n",
    "    'query': query,\n",
    "    'display': 100,\n",
    "    'sort': 'sim'\n",
    "}\n",
    "\n",
    "# 3. API 호출\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "# 4. 응답 확인 및 데이터 처리\n",
    "if response.status_code == 200:\n",
    "    items = response.json()['items']\n",
    "    \n",
    "    items_list = []\n",
    "    for item in items:\n",
    "        title = item.get('title', '').replace('<b>', '').replace('</b>', '').strip()\n",
    "        link = item.get('link', '')\n",
    "        thumbnail = item.get('thumbnail', '')\n",
    "        sizeheight = item.get('sizeheight', '')\n",
    "        sizewidth = item.get('sizewidth', '')\n",
    "        \n",
    "        items_list.append([title, link, thumbnail, sizeheight, sizewidth])\n",
    "    \n",
    "    # 5. DataFrame 생성 및 CSV 저장\n",
    "    df = pd.DataFrame(items_list, columns=['제목', '링크', '썸네일', 'sizeheight', 'sizewidth'])\n",
    "    df.to_csv('ch14_청바지.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"✅ 성공! {len(df)}건의 청바지 이미지 데이터를 'ch14_청바지.csv'로 저장했습니다.\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ 오류 발생! 상태 코드: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e0f0c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>링크</th>\n",
       "      <th>썸네일</th>\n",
       "      <th>sizeheight</th>\n",
       "      <th>sizewidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>버버리 BURBERRY 패셔너블한 클래식 캐주얼 다용도 청바지 - 위핑 버버리 BU...</td>\n",
       "      <td>https://weping.co.kr/data/editor/goods/2530/20...</td>\n",
       "      <td>https://search.pstatic.net/sunny/?type=b150&amp;sr...</td>\n",
       "      <td>1067</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   제목  \\\n",
       "54  버버리 BURBERRY 패셔너블한 클래식 캐주얼 다용도 청바지 - 위핑 버버리 BU...   \n",
       "\n",
       "                                                   링크  \\\n",
       "54  https://weping.co.kr/data/editor/goods/2530/20...   \n",
       "\n",
       "                                                  썸네일  sizeheight  sizewidth  \n",
       "54  https://search.pstatic.net/sunny/?type=b150&sr...        1067        800  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_image_list(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법2)'\n",
    "    from urllib.request import urlopen, Request\n",
    "    from urllib.parse import quote\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    encText = quote(query)\n",
    "    url = f'https://openapi.naver.com/v1/search/image?query={encText}&display=100'\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    request = Request(url, headers=headers)\n",
    "    response = urlopen(request)\n",
    "    # print(response.read().decode('utf-8'))\n",
    "    items = json.loads(response.read().decode('utf-8'))['items']\n",
    "    items_list = []\n",
    "    for item in items:\n",
    "        #print(item)\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list(\"청바지\")\n",
    "df.to_csv('data/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d44b8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>링크</th>\n",
       "      <th>썸네일</th>\n",
       "      <th>sizeheight</th>\n",
       "      <th>sizewidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>아가방 청바지 가을  로이일자핏데님바지 01R532001  50% : 아가방갤러리 에덴점</td>\n",
       "      <td>http://shop1.phinf.naver.net/20240727_152/1722...</td>\n",
       "      <td>https://search.pstatic.net/common/?type=b150&amp;s...</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   제목  \\\n",
       "59  아가방 청바지 가을  로이일자핏데님바지 01R532001  50% : 아가방갤러리 에덴점   \n",
       "\n",
       "                                                   링크  \\\n",
       "59  http://shop1.phinf.naver.net/20240727_152/1722...   \n",
       "\n",
       "                                                  썸네일  sizeheight  sizewidth  \n",
       "59  https://search.pstatic.net/common/?type=b150&s...        4000       3000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_image_list(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법1)'\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    url = 'https://openapi.naver.com/v1/search/image'\n",
    "    params = {'query':query, 'display':100 }\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    #items = response.json()['items']\n",
    "    items = json.loads(response.text)['items']\n",
    "    #print(items[0])\n",
    "    items_list = []\n",
    "    for item in items:\n",
    "        #print(item)\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list(\"청바지\")\n",
    "df.to_csv('data/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12dc1a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://shop-phinf.pstatic.net/20251015_281/1760512390478oRzer_PNG/42211957144911892_1321802660.png\n",
      "https://search.pstatic.net/common/?type=b150&src=https://shop-phinf.pstatic.net/20251015_281/1760512390478oRzer_PNG/42211957144911892_1321802660.png\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0, '링크'])\n",
    "print(df.loc[0, '썸네일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2c5cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(attr, idx, link, query):\n",
    "    'link의 이미지를 image/attr_idx_query.확장자로 local에 저장'\n",
    "    import requests\n",
    "    file_extension = link.split('.')[-1] # 확장자\n",
    "    quote_index = file_extension.find('?') # 확장자뒤에 ?가 있는 위치 .jpg?w=780\n",
    "    if quote_index != -1:\n",
    "        file_extension = file_extension[:quote_index]\n",
    "    img = requests.get(link).content # 바이너리\n",
    "    with open(f'image/{attr}_{idx+1:02}_{query}.{file_extension}', 'wb') as f:\n",
    "        f.write(img)\n",
    "save_image('메인', 0, df.loc[25, '링크'], '청바지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bc58c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = 20% 진행중 = = =\n",
      "= = = 40% 진행중 = = =\n",
      "= = = 60% 진행중 = = =\n",
      "= = = 80% 진행중 = = =\n",
      "= = = 완료 = = =\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>링크</th>\n",
       "      <th>썸네일</th>\n",
       "      <th>sizeheight</th>\n",
       "      <th>sizewidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>남자와이드청바지 남성더블턱청바지 : 설렌다</td>\n",
       "      <td>http://shop1.phinf.naver.net/20251010_63/17600...</td>\n",
       "      <td>https://search.pstatic.net/common/?type=b150&amp;s...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         제목  \\\n",
       "67  남자와이드청바지 남성더블턱청바지 : 설렌다   \n",
       "\n",
       "                                                   링크  \\\n",
       "67  http://shop1.phinf.naver.net/20251010_63/17600...   \n",
       "\n",
       "                                                  썸네일  sizeheight  sizewidth  \n",
       "67  https://search.pstatic.net/common/?type=b150&s...        1000       1000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_image_list_save_image(query):\n",
    "    'query로 검색한 이미지 정보(정보,링크,썸네일,크기) 100건 데이터 프레임을 return(방법1)'\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    client_id = os.getenv('CLIENT_ID')\n",
    "    client_secret = os.getenv('CLIENT_SECRET')\n",
    "    url = 'https://openapi.naver.com/v1/search/image'\n",
    "    params = {'query':query, 'display':100 }\n",
    "    headers = {\n",
    "        'X-Naver-Client-Id':client_id,\n",
    "        'X-Naver-Client-Secret':client_secret\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    #items = response.json()['items']\n",
    "    items = json.loads(response.text)['items']\n",
    "    items_list = [] # 정보가 담길 리스트\n",
    "    for idx, item in enumerate(items):\n",
    "        link = item.get('link')\n",
    "        thumbnail = item.get('thumbnail')\n",
    "        items_list.append({\n",
    "            '제목':item.get('title'),\n",
    "            '링크':link,\n",
    "            '썸네일': thumbnail,\n",
    "            'sizeheight': int(item.get('sizeheight')),\n",
    "            'sizewidth':  int(item.get('sizewidth')),\n",
    "        })\n",
    "        # 이미지 파일 저장\n",
    "        save_image('메인', idx, link, query)\n",
    "        save_image('썸네일', idx, thumbnail, query)\n",
    "        if (idx%20 == 0) & (idx!=0):\n",
    "            print(f'= = = {idx}% 진행중 = = =')\n",
    "    print('= = = 완료 = = =')\n",
    "    return pd.DataFrame(items_list)\n",
    "df = get_image_list_save_image(\"청바지\")\n",
    "df.to_csv('image/ch14_청바지.csv')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b987e",
   "metadata": {},
   "source": [
    "## 2.3 XML 웹데이터 수집\n",
    "- RSS /open API을 통한 XML 웹데이터 수짐\n",
    "### 1) 전국 날씨를 RSS를 BeautifalSoup을 이용한 크롤링\n",
    "- 기상청 RSS 검색한 첫번째 사이트로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95e0c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지역</th>\n",
       "      <th>1주평년기온</th>\n",
       "      <th>1주기온범위</th>\n",
       "      <th>1주낮을확률</th>\n",
       "      <th>1주비슷할확률</th>\n",
       "      <th>1주높을확률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전국(제주도,북한제외)</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.0~6.8</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울ㆍ인천ㆍ경기도</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.7~5.9</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강원도 영서</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5~3.7</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>강원도 영동</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.9~6.7</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>대전ㆍ세종ㆍ충청남도</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.5~6.3</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>충청북도</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.1~5.1</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>광주ㆍ전라남도</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.4~9.2</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>전북자치도</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.9~6.9</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>부산ㆍ울산ㆍ경상남도</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.0~8.8</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>대구ㆍ경상북도</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.8~6.6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>제주도</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.3~13.1</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>평안남북도ㆍ황해도</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6~3.0</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>함경남북도</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.1~1.3</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                지역 1주평년기온     1주기온범위 1주낮을확률 1주비슷할확률 1주높을확률\n",
       "0    전국(제주도,북한제외)     5.9    5.0~6.8     20      40     40\n",
       "1       서울ㆍ인천ㆍ경기도     4.8    3.7~5.9     20      40     40\n",
       "2          강원도 영서     2.6    1.5~3.7     20      40     40\n",
       "3          강원도 영동     5.8    4.9~6.7     20      40     40\n",
       "4      대전ㆍ세종ㆍ충청남도     5.4    4.5~6.3     20      40     40\n",
       "5            충청북도     4.1    3.1~5.1     20      40     40\n",
       "6         광주ㆍ전라남도     8.3    7.4~9.2     20      40     40\n",
       "7           전북자치도     5.9    4.9~6.9     20      40     40\n",
       "8      부산ㆍ울산ㆍ경상남도     7.9    7.0~8.8     20      40     40\n",
       "9         대구ㆍ경상북도     5.7    4.8~6.6     20      40     40\n",
       "10            제주도    12.2  11.3~13.1     20      40     40\n",
       "11      평안남북도ㆍ황해도     1.8    0.6~3.0     20      40     40\n",
       "12          함경남북도     0.1   -1.1~1.3     20      40     40"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "items_list = []\n",
    "url = 'https://www.kma.go.kr/repositary/xml/fct/mon/img/fct_mon1rss_108_20251106.xml'\n",
    "# 방법1\n",
    "# target = requests.get(url)\n",
    "# soup = BeautifulSoup(target.text, \"xml\") # pip install lxml 필요없음\n",
    "# 방법2\n",
    "target = urlopen(url)\n",
    "soup = BeautifulSoup(target, \"xml\")\n",
    "local_tas = soup.select('local_ta')\n",
    "for local_ta in local_tas:\n",
    "    local_name = local_ta.select_one('local_ta_name').text\n",
    "    week1_normalYear = local_ta.select_one('week1_local_ta_normalYear').text\n",
    "    week1_similarRange = local_ta.select_one('week1_local_ta_similarRange').text\n",
    "    week1_minVal = local_ta.select_one('week1_local_ta_minVal').text\n",
    "    week1_similarVal = local_ta.select_one('week1_local_ta_similarVal').text\n",
    "    week1_maxVal = local_ta.select_one('week1_local_ta_maxVal').text\n",
    "    items_list.append({\n",
    "        '지역':local_name,\n",
    "        '1주평년기온':week1_normalYear,\n",
    "        '1주기온범위':week1_similarRange,\n",
    "        '1주낮을확률':week1_minVal,\n",
    "        '1주비슷할확률':week1_similarVal,\n",
    "        '1주높을확률':week1_maxVal\n",
    "    })\n",
    "pd.DataFrame(items_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e78a293",
   "metadata": {},
   "source": [
    "### 2) XML 응답하는 open API 활용\n",
    "- data.go.kr에서 \n",
    "    - 서울특별시_노선정보조회 서비스(버스 ID, 정류장목록과정류장ID)\n",
    "    - 서울특별시_버스위치정보조회 서비스(실시간 버스 위치 목록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391774f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 버스번호의 버스 id 받아오기\n",
    "# 서울특별시_노선정보조회 서비스 - 3번 기능(getBusLouteList) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6b55a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# print(os.getenv('KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1a73a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fread' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m urlretrieve(url,savefilename1) \u001b[38;5;66;03m# xml 파일(url)을 savefilename으로 저장\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(savefilename1,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 12\u001b[0m     xml\u001b[38;5;241m=\u001b[39m\u001b[43mfread\u001b[49m();\n\u001b[0;32m     13\u001b[0m soup\u001b[38;5;241m=\u001b[39mBeautifulSoup(xml,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fread' is not defined"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# urlretrieve(url, 저장경로) : url파일을 저장경로에 저장\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import quote\n",
    "busNum='273'\n",
    "key=os.getenv('KEY')\n",
    "url=f'http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey={key}&strSrch={busNum}'\n",
    "savefilename1='data.ch14_busInfo.xml'\n",
    "urlretrieve(url,savefilename1) # xml 파일(url)을 savefilename으로 저장\n",
    "with open(savefilename1,encoding='utf-8') as f:\n",
    "    xml=fread();\n",
    "soup=BeautifulSoup(xml,'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597487e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busRouteId= 100100034\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "# busNum=quote('구로09')\n",
    "busNum = '162'\n",
    "key=os.getenv('KEY')\n",
    "url=f'http://ws.bus.go.kr/api/rest/busRouteInfo/getBusRouteList?ServiceKey={key}&strSrch={busNum}'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "\n",
    "for item in soup.select('itemList'):\n",
    "    busRouteNm = item.select_one('busRouteNm').text\n",
    "    if busRouteNm==busNum:\n",
    "        busRouteId=item.select_one('busRouteId').text\n",
    "        break;\n",
    "print('busRouteId=', busRouteId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cd7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step2. 버스id로 버스정류장목록받아오기(정류장명, 정류장id, 경도, 위도)\n",
    "# 서울특별시_노선정보조회 서비스 - 4번 기능(getStaionsByRouteList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24aa695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162번 정류장 갯수 : 77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정류소명</th>\n",
       "      <th>id</th>\n",
       "      <th>경도</th>\n",
       "      <th>위도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>정릉산장아파트</td>\n",
       "      <td>107000071</td>\n",
       "      <td>127.003343</td>\n",
       "      <td>37.616712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>정릉4동주민센터.경국사</td>\n",
       "      <td>107000073</td>\n",
       "      <td>127.006345</td>\n",
       "      <td>37.613529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>북한산보국문역2번출구</td>\n",
       "      <td>107000518</td>\n",
       "      <td>127.0079858233</td>\n",
       "      <td>37.612293899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>성북청수도서관.정릉4동성당</td>\n",
       "      <td>107000075</td>\n",
       "      <td>127.0084193769</td>\n",
       "      <td>37.6115696748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정릉시장입구</td>\n",
       "      <td>107000077</td>\n",
       "      <td>127.0098212542</td>\n",
       "      <td>37.6084653256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             정류소명         id              경도             위도\n",
       "0         정릉산장아파트  107000071      127.003343      37.616712\n",
       "1    정릉4동주민센터.경국사  107000073      127.006345      37.613529\n",
       "2     북한산보국문역2번출구  107000518  127.0079858233   37.612293899\n",
       "3  성북청수도서관.정릉4동성당  107000075  127.0084193769  37.6115696748\n",
       "4          정릉시장입구  107000077  127.0098212542  37.6084653256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url2 = f'http://ws.bus.go.kr/api/rest/busRouteInfo/getStaionByRoute?ServiceKey={key}&busRouteId={busRouteId}'\n",
    "response = requests.get(url2)\n",
    "soup = BeautifulSoup(response.content, 'xml')\n",
    "itemLists = soup.find_all('itemList')\n",
    "print(f'{busNum}번 정류장 갯수 : {len(itemLists)}')\n",
    "bus_station = []\n",
    "for itemList in itemLists:\n",
    "    stationNm = itemList.find('stationNm').text # 정류소 이름\n",
    "    station   = itemList.find('station').text   # 정류소 id\n",
    "    gpsX      = itemList.find('gpsX').text      # 경도\n",
    "    gpsY      = itemList.find('gpsY').text      # 위도\n",
    "    bus_station.append([stationNm, station, gpsX, gpsY])\n",
    "df_station = pd.DataFrame(bus_station, columns=['정류소명', 'id', '경도', '위도'])\n",
    "df_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076ea26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9c486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3. 버스id로 실시간위치정보를 받아오기(차량번호, 혼잡도, 최종정류장id, 다음정류장id, 도착소요시간)\n",
    "# 서울특별시_버스위치정보조회 서비스 - 2번(getBusPosByRtidList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d0aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ws.bus.go.kr/api/rest/buspos/getBusPosByRtid?serviceKey=a3209964458c3e7f385c907476fdfe24b26560cc939e346eda48357825cc1836&busRouteId=100100034\n",
      "운행중인 버스는 22대입니다\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>차량번호</th>\n",
       "      <th>혼잡도</th>\n",
       "      <th>경도</th>\n",
       "      <th>위도</th>\n",
       "      <th>최종정류소id</th>\n",
       "      <th>다음정류소id</th>\n",
       "      <th>도착소요시간</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>서울74사2244</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.011555</td>\n",
       "      <td>37.604972</td>\n",
       "      <td>107000079</td>\n",
       "      <td>107000168</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울74사3381</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.016328</td>\n",
       "      <td>37.593124</td>\n",
       "      <td>107000174</td>\n",
       "      <td>101000042</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서울74사2201</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.000884</td>\n",
       "      <td>37.585286</td>\n",
       "      <td>100000005</td>\n",
       "      <td>101000042</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서울74사1967</td>\n",
       "      <td>여유</td>\n",
       "      <td>126.986597</td>\n",
       "      <td>37.577147</td>\n",
       "      <td>100000076</td>\n",
       "      <td>101000042</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서울70사6556</td>\n",
       "      <td>여유</td>\n",
       "      <td>126.981542</td>\n",
       "      <td>37.562611</td>\n",
       "      <td>101000042</td>\n",
       "      <td>102000018</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        차량번호 혼잡도          경도         위도    최종정류소id    다음정류소id 도착소요시간\n",
       "0  서울74사2244  여유  127.011555  37.604972  107000079  107000168    172\n",
       "1  서울74사3381  여유  127.016328  37.593124  107000174  101000042   1576\n",
       "2  서울74사2201  여유  127.000884  37.585286  100000005  101000042   1165\n",
       "3  서울74사1967  여유  126.986597  37.577147  100000076  101000042    750\n",
       "4  서울70사6556  여유  126.981542  37.562611  101000042  102000018    957"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3 = f'http://ws.bus.go.kr/api/rest/buspos/getBusPosByRtid?serviceKey={key}&busRouteId={busRouteId}'\n",
    "print(url3)\n",
    "response = requests.get(url3)\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "itemLists = soup.select('itemList')\n",
    "print(f'운행중인 버스는 {len(itemLists)}대입니다')\n",
    "bus_position = []\n",
    "for itemList in itemLists:\n",
    "    plainNo = itemList.select_one('plainNo').text # 차량번호\n",
    "    congetion = itemList.select_one('congetion').text # 혼잡도(congetion)\n",
    "    # 0 : 없음, 3 : 여유, 4 : 보통, 5 : 혼잡, 6 : 매우혼잡\n",
    "    congetion = '없음' if congetion=='0' \\\n",
    "            else '여유' if congetion=='3' \\\n",
    "            else '보통' if congetion=='4' \\\n",
    "            else '혼잡' if congetion=='5' else '매우혼잡'\n",
    "    gpsX = itemList.select_one('gpsX').text # 경도\n",
    "    gpsY = itemList.select_one('gpsY').text # 위도\n",
    "    lastStnId = itemList.select_one('lastStnId').text # 최종정류소id\n",
    "    nextStId = itemList.select_one('nextStId').text # 다음정류소id\n",
    "    nextStTm = itemList.select_one('nextStTm').text # 다음정류소까지 소요시간\n",
    "    \n",
    "    bus_position.append({\n",
    "        '차량번호':plainNo,\n",
    "        '혼잡도':congetion,\n",
    "        '경도':gpsX,\n",
    "        '위도':gpsY,\n",
    "        '최종정류소id':lastStnId,\n",
    "        '다음정류소id':nextStId,\n",
    "        '도착소요시간':nextStTm\n",
    "    })\n",
    "df_position = pd.DataFrame(bus_position)\n",
    "df_position.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba19f791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정류소명</th>\n",
       "      <th>id</th>\n",
       "      <th>경도</th>\n",
       "      <th>위도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>북한산보국문역2번출구</td>\n",
       "      <td>107000518</td>\n",
       "      <td>127.0079858233</td>\n",
       "      <td>37.612293899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          정류소명         id              경도            위도\n",
       "2  북한산보국문역2번출구  107000518  127.0079858233  37.612293899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station.loc[df_station['id']=='107000518']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae76edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    북한산보국문역2번출구\n",
       "Name: 정류소명, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station.loc[df_station['id']=='107000518', '정류소명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaee6805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'북한산보국문역2번출구'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station.loc[df_station['id']=='107000518', '정류소명'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e95d417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정릉우체국앞'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_station.loc[df_station['id']=='107000079', '정류소명'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ee28131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차량번호        서울74사2244\n",
      "혼잡도                여유\n",
      "경도         127.011555\n",
      "위도          37.604972\n",
      "최종정류소id     107000079\n",
      "다음정류소id     107000168\n",
      "도착소요시간            172\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def station_name(row):\n",
    "    'row의 최종정류소명과 다음정류소명을 추가하여 return'\n",
    "    print(row)\n",
    "station_name(df_position.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3c6a19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량번호           서울74사2201\n",
       "혼잡도                   여유\n",
       "경도            127.000884\n",
       "위도             37.585286\n",
       "최종정류소id        100000005\n",
       "다음정류소id        101000042\n",
       "도착소요시간              1165\n",
       "이전정류소명     혜화동로터리.여운형활동터\n",
       "다음정류소명       해운센터.롯데영플라자\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def station_name(row):\n",
    "    'row의 최종정류소명과 다음정류소명을 추가하고, 도착소요시간을  분으로 바꿔 return'\n",
    "    row['이전정류소명']=df_station.loc[df_station['id']==row['최종정류소id'],'정류소명'].iloc[0]\n",
    "    row['다음정류소명']=df_station.loc[df_station['id']==row['다음정류소id'],'정류소명'].iloc[0]\n",
    "    return row\n",
    "station_name(df_position.loc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a351adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "차량번호           서울74사2201\n",
       "혼잡도                   여유\n",
       "경도            127.000884\n",
       "위도             37.585286\n",
       "최종정류소id        100000005\n",
       "다음정류소id        101000042\n",
       "도착소요시간              1165\n",
       "이전정류소명     혜화동로터리.여운형활동터\n",
       "다음정류소명       해운센터.롯데영플라자\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def station_name(row):\n",
    "    'row의 최종정류소명과 다음정류소명을 추가하고, 도착소요시간을  분으로 바꿔 return'\n",
    "    row['이전정류소명']=df_station.loc[df_station['id']==row['최종정류소id'],'정류소명'].iloc[0]\n",
    "    row['다음정류소명']=df_station.loc[df_station['id']==row['다음정류소id'],'정류소명'].iloc[0]\n",
    "    print(round(float(row['도착소요시간'])/60))\n",
    "    return row\n",
    "station_name(df_position.loc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "195360a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량번호              서울74사1625\n",
       "혼잡도                      여유\n",
       "경도               127.008204\n",
       "위도                37.589259\n",
       "최종정류소id           107000010\n",
       "다음정류소id           107000171\n",
       "도착소요시간                8분27초\n",
       "이전정류소명     삼선교.한성대학교.조소앙활동터\n",
       "다음정류소명     아리랑고개.아리랑시네미디어센터\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def station_name(row):\n",
    "    row = row.copy()\n",
    "    'row의 최종정류소명과 다음정류소명을 추가하고, 도착소요시간을 분으로 바꿔 return'\n",
    "    row['이전정류소명'] = df_station.loc[df_station['id']==row['최종정류소id'],'정류소명'].iloc[0]\n",
    "    row['다음정류소명'] = df_station.loc[df_station['id']==row['다음정류소id'],'정류소명'].iloc[0]\n",
    "    minite = int(row['도착소요시간'])//60 # //몫연산자\n",
    "    sec    = int(row['도착소요시간']) % 60\n",
    "    row['도착소요시간'] = f'{minite}분{sec}초'\n",
    "    return row\n",
    "station_name(df_position.loc[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba12a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_name(row):\n",
    "    row = row.copy()\n",
    "    'row의 최종정류소명과 다음정류소명을 추가하고, 도착소요시간을 분으로 바꿔 return'\n",
    "    row['이전정류소명'] = df_station.loc[df_station['id']==row['최종정류소id'],'정류소명'].iloc[0]\n",
    "    row['다음정류소명'] = df_station.loc[df_station['id']==row['다음정류소id'],'정류소명'].iloc[0]\n",
    "    minite = int(row['도착소요시간'])//60 # //몫연산자\n",
    "    sec    = int(row['도착소요시간']) % 60\n",
    "    row['도착소요시간'] = f'{minite}분{sec}초'\n",
    "    return row\n",
    "#station_name(df_position.loc[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1ce21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>차량번호</th>\n",
       "      <th>혼잡도</th>\n",
       "      <th>경도</th>\n",
       "      <th>위도</th>\n",
       "      <th>도착소요시간</th>\n",
       "      <th>이전정류소명</th>\n",
       "      <th>다음정류소명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>서울74사2244</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.011555</td>\n",
       "      <td>37.604972</td>\n",
       "      <td>2분52초</td>\n",
       "      <td>정릉우체국앞</td>\n",
       "      <td>정릉입구.정릉역</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울74사3381</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.016328</td>\n",
       "      <td>37.593124</td>\n",
       "      <td>26분16초</td>\n",
       "      <td>성신여대입구역5번출구</td>\n",
       "      <td>해운센터.롯데영플라자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서울74사2201</td>\n",
       "      <td>여유</td>\n",
       "      <td>127.000884</td>\n",
       "      <td>37.585286</td>\n",
       "      <td>19분25초</td>\n",
       "      <td>혜화동로터리.여운형활동터</td>\n",
       "      <td>해운센터.롯데영플라자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서울74사1967</td>\n",
       "      <td>여유</td>\n",
       "      <td>126.986597</td>\n",
       "      <td>37.577147</td>\n",
       "      <td>12분30초</td>\n",
       "      <td>창덕궁.우리소리박물관</td>\n",
       "      <td>해운센터.롯데영플라자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서울70사6556</td>\n",
       "      <td>여유</td>\n",
       "      <td>126.981542</td>\n",
       "      <td>37.562611</td>\n",
       "      <td>15분57초</td>\n",
       "      <td>해운센터.롯데영플라자</td>\n",
       "      <td>남영역.민주화운동기념관</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        차량번호 혼잡도          경도         위도  도착소요시간         이전정류소명        다음정류소명\n",
       "0  서울74사2244  여유  127.011555  37.604972   2분52초         정릉우체국앞      정릉입구.정릉역\n",
       "1  서울74사3381  여유  127.016328  37.593124  26분16초    성신여대입구역5번출구   해운센터.롯데영플라자\n",
       "2  서울74사2201  여유  127.000884  37.585286  19분25초  혜화동로터리.여운형활동터   해운센터.롯데영플라자\n",
       "3  서울74사1967  여유  126.986597  37.577147  12분30초    창덕궁.우리소리박물관   해운센터.롯데영플라자\n",
       "4  서울70사6556  여유  126.981542  37.562611  15분57초    해운센터.롯데영플라자  남영역.민주화운동기념관"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_position.apply(station_name, axis=1)\n",
    "df.drop(['최종정류소id','다음정류소id'], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a955e",
   "metadata": {},
   "source": [
    "# 3절 연습문제(Quiz1)\n",
    "* yes24의 베스트셀러 정보를 제공하는 사이트에서 베스트셀러 정보를 수집해서 파일에 저장하세요.\n",
    "* 베스트셀러 정보 수집 주소 : http://www.yes24.com/24/category/bestseller (1페이지만 추출)\n",
    "* https://www.yes24.com/product/category/bestseller?pageNumber={page} (여러 페이지 추출)\n",
    "*ch14_yes24.csv나 ch14_yes24.txt의 내용(구분문자를 ,나 \\t,....)\n",
    "    - 순위,책이름,저자,출판사,가격\n",
    "      1,[도서]트렌드코리아2026,\"김난도,전미영,최지혜,권정윤,한다혜, 미래의창\",18,000원\n",
    "      24,[만화]그 비스트 어쩌구,후쿠다신이치글그림/박연지역, 소미미디어,25,200원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e37db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c33b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름\n",
      "10 번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>책이름</th>\n",
       "      <th>저자</th>\n",
       "      <th>출판사</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>트렌드 코리아 2026</td>\n",
       "      <td>김난도, 전미영, 최지혜, 권정윤, 한다혜 저 외 7명</td>\n",
       "      <td>미래의창</td>\n",
       "      <td>18,000원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   순위           책이름                              저자   출판사       가격\n",
       "0   1  트렌드 코리아 2026  김난도, 전미영, 최지혜, 권정윤, 한다혜 저 외 7명  미래의창  18,000원"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1\n",
    "pages = 2\n",
    "bestseller_list = []\n",
    "with open('data/ch14_yes24.txt', 'w', encoding='utf-8') as f:\n",
    "    pass\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://www.yes24.com/product/category/bestseller?pageNumber={page}'\n",
    "    #print(url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # 순위\n",
    "    ranks_els = soup.select('div.img_upper > em.ico.rank')\n",
    "    ranks =  [int(ranks_el.text) for ranks_el in ranks_els]\n",
    "    # 책제목\n",
    "    titles_els=soup.select(\"div.info_row > a.gd_name\")\n",
    "    titles = [titles_el.text for titles_el in titles_els]\n",
    "    # 저자\n",
    "    authors_els = soup.select('span.authPub.info_auth')\n",
    "    authors = [authors_el.text.strip() for authors_el in authors_els]\n",
    "    # authors = [authors_el.get_text(strip=True) for authors_el in authors_els]\n",
    "#     print(authors)\n",
    "    for i, author in enumerate(authors):\n",
    "        match = re.search(r\"(.*)외 \\d+명\", author)\n",
    "        if(match):\n",
    "            authors[i] = match.group()\n",
    "            print(i, '번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름')\n",
    "    # 출판사\n",
    "    publishers_els = soup.select('div.info_row.info_pubGrp > span.authPub.info_pub')\n",
    "    publishers = [publishers_el.text for publishers_el in publishers_els]\n",
    "    # 가격\n",
    "    prices_els = soup.select(\"div.info_row > strong.txt_num\")\n",
    "    prices = [prices_el.text for prices_el in prices_els]\n",
    "    \n",
    "    # print(len(ranks), len(titles), len(writers), len(publishers), len(prices))\n",
    "    with open('data/ch14_yes24.txt', 'a', encoding='utf-8') as f:\n",
    "        for rank, title, author, publisher, price in zip(ranks, titles, authors, publishers, prices):\n",
    "            # print(\"{:02},{},{} | {},{}\".format(rank, title, author, publisher, price))\n",
    "            f.write(f'{rank}, {title}, {author} | {publisher}, {price}\\n')\n",
    "            bestseller_list.append([rank, title, author, publisher, price])\n",
    "df = pd.DataFrame(bestseller_list, columns=['순위','책이름','저자','출판사','가격'])\n",
    "df.to_csv('data/ch14_yes24.csv', index=False)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20c5d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>책이름</th>\n",
       "      <th>저자</th>\n",
       "      <th>출판사</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>트렌드 코리아 2026</td>\n",
       "      <td>김난도, 전미영, 최지혜, 권정윤, 한다혜 저 외 7명</td>\n",
       "      <td>미래의창</td>\n",
       "      <td>18,000원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   순위           책이름                              저자   출판사       가격\n",
       "0   1  트렌드 코리아 2026  김난도, 전미영, 최지혜, 권정윤, 한다혜 저 외 7명  미래의창  18,000원"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법2\n",
    "pages = 2\n",
    "bestseller_list = []\n",
    "with open('data/ch14_yes24.txt', 'w', encoding='utf-8') as f:\n",
    "    pass\n",
    "for page in range(1, pages+1):\n",
    "    url = f'https://www.yes24.com/product/category/bestseller?pageNumber={page}'\n",
    "    #print(url)\n",
    "    response = urlopen(url)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    # 순위\n",
    "    ranks_els = soup.select('div.img_upper > em.ico.rank')\n",
    "    ranks =  [int(ranks_el.text) for ranks_el in ranks_els]\n",
    "    # 책제목\n",
    "    titles_els=soup.select(\"div.info_row > a.gd_name\")\n",
    "    titles = [titles_el.text for titles_el in titles_els]\n",
    "    # 저자\n",
    "    authors_els = soup.select('span.authPub.info_auth')\n",
    "    authors = [authors_el.text.split('정보 더 보기/감추기')[0].strip() \n",
    "                                   for authors_el in authors_els]\n",
    "#     for i, author in enumerate(authors):\n",
    "#         match = re.search(r\"(.*)외 \\d+명\", author)\n",
    "#         if(match):\n",
    "#             authors[i] = match.group()\n",
    "#             print(i, '번째 도서의 저자가 많아 외 x명 뒤에도 길어 그 앞까지 짜름')\n",
    "    # 출판사\n",
    "    publishers_els = soup.select('div.info_row.info_pubGrp > span.authPub.info_pub')\n",
    "    publishers = [publishers_el.text for publishers_el in publishers_els]\n",
    "    # 가격\n",
    "    prices_els = soup.select(\"div.info_row > strong.txt_num\")\n",
    "    prices = [prices_el.text for prices_el in prices_els]\n",
    "    # print(len(ranks), len(titles), len(writers), len(publishers), len(prices))\n",
    "    with open('data/ch14_yes24.txt', 'a', encoding='utf-8') as f:\n",
    "        for rank, title, author, publisher, price in zip(ranks, titles, authors, publishers, prices):\n",
    "            # print(\"{:02},{},{} | {},{}\".format(rank, title, author, publisher, price))\n",
    "            f.write(f'{rank}, {title}, {author} | {publisher}, {price}\\n')\n",
    "            bestseller_list.append([rank, title, author, publisher, price])\n",
    "df = pd.DataFrame(bestseller_list, columns=['순위','책이름','저자','출판사','가격'])\n",
    "df.to_csv('data/ch14_yes24.csv', index=False)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b348e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (연습문제)(퀴즈1)yes24 의 베스트셀러 정보를 제공하는 사이트에서 베스트셀러 정보를 수집해서 파일에 저장하세요\n",
    "# 베스트셀러 정보 수집 주소 : http://www.yes24.com/24/category/bestseller\n",
    "# csv\n",
    "# 순위,제목,저자,출판사,판매가,판매지수\n",
    "# 1,\"책 먹는 여우 식당 1\",\"정민\",\"창비\",\"10,800원\",\"1,234\"\n",
    "# 2,\"책 먹는 여우 식당 2\",\"정민\",\"창비\",\"12,600원\",\"1,156\"\n",
    "# 3,\"사장학개론\",\"김슬아\",\"북라이프\",\"16,200원\",\"980\"\n",
    "# 4,\"메리골드 마음 세탁소\",\"윤정은\",\"모모\",\"13,500원\",\"875\"\n",
    "# 5,\"디 에센셜 스위트\",\"이지영\",\"위즈덤하우스\",\"19,800원\",\"792\"\n",
    "# 6,\"아침을 깨우는 말\",\"이태훈\",\"포레스트북스\",\"14,400원\",\"723\"\n",
    "# 7,\"마흔 살의 여름\",\"한강\",\"문학동네\",\"15,300원\",\"689\"\n",
    "# 8,\"달러구트 꿈 백화점 이미예\",\"이미예\",\"북토피아\",\"13,800원\",\"654\"\n",
    "# 9,\"당신의 마음이 따뜻해지는 책\",\"알라딘\",\"알라딘\",\"12,000원\",\"623\"\n",
    "# 10,\"작별하지 않는다\",\"한강\",\"문학동네\",\"14,850원\",\"589\"\n",
    "# 11,\"채식주의자\",\"한강\",\"문학동네\",\"13,500원\",\"567\"\n",
    "# 12,\"소년이 온다\",\"한강\",\"문학동네\",\"12,600원\",\"534\"\n",
    "# 13,\"여행의 이유\",\"김영하\",\"문학동네\",\"14,400원\",\"498\"\n",
    "# 14,\"여행의 시간\",\"김영하\",\"문학동네\",\"15,300원\",\"456\"\n",
    "# 15,\"밤의 여섯 시간\",\"미야베 미유키\",\"은행나무\",\"17,100원\",\"423\"\n",
    "# 16,\"달러구트 꿈 백화점 2\",\"이미예\",\"북토피아\",\"14,850원\",\"389\"\n",
    "# 17,\"바깥은 여름\",\"김애란\",\"문학동네\",\"13,500원\",\"356\"\n",
    "# 18,\"아몬드\",\"손원평\",\"창비\",\"13,800원\",\"324\"\n",
    "# 19,\"연금술사\",\"파울로 코엘료\",\"문학동네\",\"12,600원\",\"298\"\n",
    "# 20,\"불편한 편의점\",\"김호연\",\"나무옆의자\",\"14,400원\",\"267\"\n",
    "# 21,\"달러구트 꿈 백화점 3\",\"이미예\",\"북토피아\",\"15,300원\",\"234\"\n",
    "# 22,\"빛의 제국\",\"김영하\",\"문학동네\",\"16,200원\",\"198\"\n",
    "# 23,\"여행의 기술\",\"알랭 드 보통\",\"을유문화사\",\"15,300원\",\"165\"\n",
    "# 24,\"해리 포터와 마법사의 돌\",\"J.K. 롤링\",\"문학수첩\",\"14,400원\",\"156\"\n",
    "# 25,\"책 먹는 여우 식당 3\",\"정민\",\"창비\",\"14,400원\",\"145\"\n",
    "# 26,\"메리골드 마음 세탁소 2\",\"윤정은\",\"모모\",\"14,850원\",\"134\"\n",
    "# 27,\"사장학개론 2\",\"김슬아\",\"북라이프\",\"17,100원\",\"123\"\n",
    "# 28,\"달러구트 꿈 백화점 4\",\"이미예\",\"북토피아\",\"16,200원\",\"112\"\n",
    "# 29,\"당신의 마음이 따뜻해지는 책 2\",\"알라딘\",\"알라딘\",\"13,500원\",\"101\"\n",
    "# 30,\"작별하지 않는다 2\",\"한강\",\"문학동네\",\"15,300원\",\"98\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8790a051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c212e1dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2846685738.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[46], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    body { font-family: Arial, sans-serif; margin: 20px; }\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# (연습문제)(퀴즈1)yes24 의 베스트셀러 정보를 제공하는 사이트에서 베스트셀러 정보를 수집해서 파일에 저장하세요.\n",
    "# 베스트셀러 정보 수집 주소 : http://www.yes24.com/24/category/bestseller\n",
    "# HTML\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ko\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Yes24 베스트셀러 데이터</title>\n",
    "    <style>\n",
    "        body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "        table { border-collapse: collapse; width: 100%; }\n",
    "        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n",
    "        th { background-color: #4CAF50; color: white; }\n",
    "        tr:nth-child(even) { background-color: #f2f2f2; }\n",
    "        .container { max-width: 1200px; margin: 0 auto; }\n",
    "        input { margin: 20px 0; padding: 10px; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>Yes24 베스트셀러 데이터</h1>\n",
    "        <input type=\"file\" id=\"csvFile\" accept=\".csv\">\n",
    "        <table id=\"bookTable\">\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>순위</th>\n",
    "                    <th>제목</th>\n",
    "                    <th>저자</th>\n",
    "                    <th>출판사</th>\n",
    "                    <th>판매가</th>\n",
    "                    <th>판매지수</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody></tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        document.getElementById('csvFile').addEventListener('change', function(e) {\n",
    "            const file = e.target.files[0];\n",
    "            if (!file) return;\n",
    "            \n",
    "            const reader = new FileReader();\n",
    "            reader.onload = function(e) {\n",
    "                const data = e.target.result;\n",
    "                const rows = data.split('\\n').slice(1);\n",
    "                const tbody = document.querySelector('#bookTable tbody');\n",
    "                tbody.innerHTML = '';\n",
    "                \n",
    "                rows.forEach(row => {\n",
    "                    if(row.trim()) {\n",
    "                        const cols = row.split(',');\n",
    "                        const tr = document.createElement('tr');\n",
    "                        cols.forEach(col => {\n",
    "                            const td = document.createElement('td');\n",
    "                            td.textContent = col.replace(/\"/g, '');\n",
    "                            tr.appendChild(td);\n",
    "                        });\n",
    "                        tbody.appendChild(tr);\n",
    "                    }\n",
    "                });\n",
    "            };\n",
    "            reader.readAsText(file);\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b084a503",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 현재 페이지 구조 ===\n",
      "제목:  국내도서 종합 베스트 - 예스24 \n",
      "\n",
      "선택자 '.item' → 9개 항목 발견\n",
      "첫 번째 항목 샘플:\n",
      "<span class=\"item\">\n",
      " 도서/음반\n",
      "</span>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (연습문제)(퀴즈1)yes24 의 베스트셀러 정보를 제공하는 사이트에서 베스트셀러 정보를 수집해서 파일에 저장하세요\n",
    "# 베스트셀러 정보 수집 주소 : http://www.yes24.com/24/category/bestseller\n",
    "# PYTHON\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 디버깅용 코드 - 현재 페이지 구조 확인\n",
    "url = \"http://www.yes24.com/24/category/bestseller?PageNumber=1\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "print(\"=== 현재 페이지 구조 ===\")\n",
    "print(f\"제목: {soup.title.text}\")\n",
    "\n",
    "# 가능한 모든 책 컨테이너 찾기\n",
    "selectors = ['.goodsItem', '.goods_item', '.goodsInfo', '.item', 'li', 'tr']\n",
    "for selector in selectors:\n",
    "    items = soup.select(selector)\n",
    "    if items:\n",
    "        print(f\"\\n선택자 '{selector}' → {len(items)}개 항목 발견\")\n",
    "        print(\"첫 번째 항목 샘플:\")\n",
    "        print(items[0].prettify()[:500])  # 첫 500자만 출력\n",
    "        break\n",
    "else:\n",
    "    print(\"\\n❌ 모든 선택자 실패 - 수동으로 HTML 구조를 확인해야 합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ade30041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68129c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📚 Yes24 베스트셀러 크롤러 시작\n",
      "============================================================\n",
      "\n",
      "📥 페이지 1 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=1\n",
      "  ❌ 모든 선택자 실패 - 페이지 구조 확인 필요\n",
      "\n",
      "📥 페이지 2 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=2\n",
      "  ❌ 모든 선택자 실패 - 페이지 구조 확인 필요\n",
      "\n",
      "📥 페이지 3 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=3\n",
      "  ❌ 모든 선택자 실패 - 페이지 구조 확인 필요\n",
      "\n",
      "❌ 수집된 데이터가 없습니다. 웹사이트 구조를 확인해주세요.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def scrape_yes24_bestseller(pages=3):\n",
    "    \"\"\"\n",
    "    Yes24 베스트셀러 정보를 수집하여 CSV와 HTML 파일을 동시 생성\n",
    "    - robust한 오류 처리\n",
    "    - 웹 구조 변화에 대응하는 대체 선택자\n",
    "    - CORS 문제 해결을 위한 데이터 직접 삽입 방식\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"📚 Yes24 베스트셀러 크롤러 시작\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    books_data = []\n",
    "    base_url = \"http://www.yes24.com/24/category/bestseller\"\n",
    "    \n",
    "    # 각 페이지 순회\n",
    "    for page in range(1, pages + 1):\n",
    "        url = f\"{base_url}?PageNumber={page}\"\n",
    "        print(f\"\\n📥 페이지 {page} 크롤링 중: {url}\")\n",
    "        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        \n",
    "        try:\n",
    "            # 요청 및 응답\n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # ✅ 여러 선택자 시도 (대체 선택자 fallback)\n",
    "            books = []\n",
    "            selectors = ['.goodsItem', '.goods_item', '#category_layout .item', 'ul#yesList li']\n",
    "            \n",
    "            for selector in selectors:\n",
    "                books = soup.select(selector)\n",
    "                if books:\n",
    "                    print(f\"  ✅ 선택자 '{selector}'로 {len(books)}개 도서 발견\")\n",
    "                    break\n",
    "            \n",
    "            if not books:\n",
    "                print(\"  ❌ 모든 선택자 실패 - 페이지 구조 확인 필요\")\n",
    "                continue\n",
    "            \n",
    "            # 각 도서 정보 추출\n",
    "            for idx, book in enumerate(books, 1):\n",
    "                try:\n",
    "                    # 순위\n",
    "                    rank_elem = book.select_one('.num') or book.select_one('.yes_b') or book.select_one('span:first-child')\n",
    "                    rank = rank_elem.text.strip() if rank_elem else str((page-1)*24 + idx)\n",
    "                    \n",
    "                    # 제목\n",
    "                    title_elem = book.select_one('.goods_name a') or book.select_one('.title a') or book.select_one('a[target=\"yes24\"]')\n",
    "                    title = title_elem.text.strip() if title_elem else '정보없음'\n",
    "                    \n",
    "                    # 저자/출판사\n",
    "                    author, publisher = '정보없음', '정보없음'\n",
    "                    info_elem = book.select_one('.goods_info') or book.select_one('.aupu') or book.select_one('.info')\n",
    "                    if info_elem:\n",
    "                        info_text = info_elem.get_text('|', strip=True)\n",
    "                        parts = [p.strip() for p in info_text.split('|') if p.strip()]\n",
    "                        if len(parts) >= 2:\n",
    "                            author = parts[0].replace('저자', '').replace(':', '').strip()\n",
    "                            publisher = parts[1].replace('출판사', '').replace(':', '').strip()\n",
    "                    \n",
    "                    # 가격\n",
    "                    price_elem = book.select_one('.yes_m') or book.select_one('.price .yes_m') or book.select_one('.emph_red')\n",
    "                    price = price_elem.text.strip() if price_elem else '0원'\n",
    "                    \n",
    "                    # 판매지수\n",
    "                    sales_elem = book.select_one('.saleNum') or book.select_one('.sale_num') or book.select_one('.num:last-child')\n",
    "                    sales_point = sales_elem.text.strip() if sales_elem else '0'\n",
    "                    \n",
    "                    # 데이터 추가\n",
    "                    books_data.append([rank, title, author, publisher, price, sales_point])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ⚠️  도서 {idx} 처리 중 오류: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # 서버 부하 방지\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"  ❌ 네트워크 오류: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ 예상치 못한 오류: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 결과 저장\n",
    "    if books_data:\n",
    "        save_csv(books_data)\n",
    "        save_html(books_data)\n",
    "    else:\n",
    "        print(\"\\n❌ 수집된 데이터가 없습니다. 웹사이트 구조를 확인해주세요.\")\n",
    "    \n",
    "    return books_data\n",
    "\n",
    "def save_csv(data):\n",
    "    \"\"\"CSV 파일 저장\"\"\"\n",
    "    filename = 'ch14_yes24.csv'\n",
    "    with open(filename, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['순위', '제목', '저자', '출판사', '판매가', '판매지수'])\n",
    "        writer.writerows(data)\n",
    "    print(f\"\\n✅ CSV 저장 완료: {filename}\")\n",
    "\n",
    "def save_html(data):\n",
    "    \"\"\"HTML 파일 저장 (데이터 직접 삽입 - CORS 문제 해결)\"\"\"\n",
    "    filename = 'yes24_bestseller.html'\n",
    "    \n",
    "    # HTML 템플릿\n",
    "    html_template = '''<!DOCTYPE html>\n",
    "<html lang=\"ko\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Yes24 베스트셀러 TOP {count}</title>\n",
    "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        body {{ background: #f8f9fa; padding: 20px; }}\n",
    "        .container {{ max-width: 1200px; background: white; border-radius: 10px; padding: 30px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); }}\n",
    "        h1 {{ color: #2c3e50; text-align: center; margin-bottom: 30px; font-weight: bold; }}\n",
    "        .stats {{ text-align: center; font-size: 20px; color: #7f8c8d; margin-bottom: 30px; }}\n",
    "        th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; text-align: center; }}\n",
    "        tr:hover {{ background-color: #f1f2f6; }}\n",
    "        td {{ vertical-align: middle; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>📚 Yes24 베스트셀러</h1>\n",
    "        <div class=\"stats\">총 {count}개의 도서 정보</div>\n",
    "        <div class=\"table-responsive\">\n",
    "            <table class=\"table table-hover align-middle\">\n",
    "                <thead>\n",
    "                    <tr>\n",
    "                        <th>순위</th>\n",
    "                        <th>제목</th>\n",
    "                        <th>저자</th>\n",
    "                        <th>출판사</th>\n",
    "                        <th>판매가</th>\n",
    "                        <th>판매지수</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>'''\n",
    "    \n",
    "    # 데이터 행 추가\n",
    "    rows_html = ''\n",
    "    for book in data:\n",
    "        rows_html += f'''\n",
    "                    <tr>\n",
    "                        <td class=\"text-center fw-bold\">{book[0]}</td>\n",
    "                        <td>{book[1]}</td>\n",
    "                        <td>{book[2]}</td>\n",
    "                        <td>{book[3]}</td>\n",
    "                        <td class=\"text-end text-danger fw-bold\">{book[4]}</td>\n",
    "                        <td class=\"text-end\">{book[5]}</td>\n",
    "                    </tr>'''\n",
    "    \n",
    "    # HTML 완성\n",
    "    html_complete = html_template + rows_html + '''\n",
    "                </tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "        <div class=\"text-center mt-4 text-muted\">\n",
    "            <small>생성 시간: ''' + time.strftime('%Y-%m-%d %H:%M:%S') + '''</small>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>'''\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_complete)\n",
    "    \n",
    "    print(f\"✅ HTML 저장 완료: {filename}\")\n",
    "    print(f\"🌐 파일을 더블클릭하여 브라우저에서 바로 확인하세요!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 실행\n",
    "    books = scrape_yes24_bestseller(pages=3)\n",
    "    \n",
    "    if books:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🎉 모든 작업 완료!\")\n",
    "        print(f\"📊 수집된 도서 수: {len(books)}권\")\n",
    "        print(\"📁 생성된 파일:\")\n",
    "        print(\"   - ch14_yes24.csv\")\n",
    "        print(\"   - yes24_bestseller.html\")\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "521ff01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📚 Yes24 베스트셀러 크롤러 시작\n",
      "============================================================\n",
      "\n",
      "📥 페이지 1 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=1\n",
      "  페이지 제목:  국내도서 종합 베스트 - 예스24 \n",
      "  ❌ 모든 선택자 실패 - 페이지 구조가 크게 변경되었습니다.\n",
      "\n",
      "--- HTML 구조 분석 (상위 500자) ---\n",
      "<!DOCTYPE html >\n",
      "<html lang=\"ko\">\n",
      " <head>\n",
      "  <link href=\"https://m.yes24.com/Home/Best?DispNo=001\" media=\"only screen and(max-width: 640px)\" rel=\"alternate\"/>\n",
      "  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <meta content=\"dpr, width, viewport-width, rtt, downlink, ect, UA, UA-Platform, UA-Arch, UA-Model, UA-Mobile, UA-Full-Version\" http-equiv=\"Accept-CH\"/>\n",
      "  <meta content=\"86400\" http-equiv=\"Accept-CH-Lifetime\"/>\n",
      "  <\n",
      "--- END ---\n",
      "\n",
      "\n",
      "📥 페이지 2 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=2\n",
      "  페이지 제목:  국내도서 종합 베스트 - 예스24 \n",
      "  ❌ 모든 선택자 실패 - 페이지 구조가 크게 변경되었습니다.\n",
      "\n",
      "--- HTML 구조 분석 (상위 500자) ---\n",
      "<!DOCTYPE html >\n",
      "<html lang=\"ko\">\n",
      " <head>\n",
      "  <link href=\"https://m.yes24.com/Home/Best?DispNo=001\" media=\"only screen and(max-width: 640px)\" rel=\"alternate\"/>\n",
      "  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <meta content=\"dpr, width, viewport-width, rtt, downlink, ect, UA, UA-Platform, UA-Arch, UA-Model, UA-Mobile, UA-Full-Version\" http-equiv=\"Accept-CH\"/>\n",
      "  <meta content=\"86400\" http-equiv=\"Accept-CH-Lifetime\"/>\n",
      "  <\n",
      "--- END ---\n",
      "\n",
      "\n",
      "📥 페이지 3 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=3\n",
      "  페이지 제목:  국내도서 종합 베스트 - 예스24 \n",
      "  ❌ 모든 선택자 실패 - 페이지 구조가 크게 변경되었습니다.\n",
      "\n",
      "--- HTML 구조 분석 (상위 500자) ---\n",
      "<!DOCTYPE html >\n",
      "<html lang=\"ko\">\n",
      " <head>\n",
      "  <link href=\"https://m.yes24.com/Home/Best?DispNo=001\" media=\"only screen and(max-width: 640px)\" rel=\"alternate\"/>\n",
      "  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <meta content=\"dpr, width, viewport-width, rtt, downlink, ect, UA, UA-Platform, UA-Arch, UA-Model, UA-Mobile, UA-Full-Version\" http-equiv=\"Accept-CH\"/>\n",
      "  <meta content=\"86400\" http-equiv=\"Accept-CH-Lifetime\"/>\n",
      "  <\n",
      "--- END ---\n",
      "\n",
      "\n",
      "❌ 최종: 수집된 데이터가 전혀 없습니다.\n",
      "ℹ️  해결 방법:\n",
      "   1. 인터넷 연결 확인\n",
      "   2. 브라우저에서 해당 URL 접속 가능 여부 확인\n",
      "   3. Yes24 웹사이트 구조가 크게 변경되었을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def scrape_yes24_bestseller(pages=3):\n",
    "    \"\"\"\n",
    "    Yes24 베스트셀러 정보를 수집하여 CSV와 HTML 파일을 동시 생성\n",
    "    수정사항:\n",
    "    - 가장 안정적인 선택자 전략 적용\n",
    "    - 오류 발생 시 HTML 구조 자동 분석\n",
    "    - 빈 데이터 발생 시 자동 복구 로직\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"📚 Yes24 베스트셀러 크롤러 시작\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    books_data = []\n",
    "    base_url = \"http://www.yes24.com/24/category/bestseller\"\n",
    "    \n",
    "    # 현재 Yes24 실제 구조에 맞는 선택자 (2025년 11월 기준)\n",
    "    # Yes24는 #yesList > li 구조를 사용\n",
    "    container_selectors = [\n",
    "        '#yesList > li',           # 가장 정확한 선택자\n",
    "        'ul#yesList li',           # 대체 선택자\n",
    "        '.yesGoods',               # 예전 구조 호환\n",
    "        '#category_layout .item'   # 최후의 복구 선택자\n",
    "    ]\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        url = f\"{base_url}?PageNumber={page}\"\n",
    "        print(f\"\\n📥 페이지 {page} 크롤링 중: {url}\")\n",
    "        \n",
    "        # User-Agent 설정 (실제 브라우저 처럼 보이도록)\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # 디버깅: 페이지 제목 확인\n",
    "            print(f\"  페이지 제목: {soup.title.text if soup.title else '제목 없음'}\")\n",
    "            \n",
    "            # 책 컨테이너 찾기 (대체 선택자 순차 시도)\n",
    "            books = []\n",
    "            selected_selector = \"\"\n",
    "            \n",
    "            for selector in container_selectors:\n",
    "                books = soup.select(selector)\n",
    "                if books:\n",
    "                    selected_selector = selector\n",
    "                    print(f\"  ✅ 선택자 '{selector}'로 {len(books)}개 도서 발견\")\n",
    "                    break\n",
    "            \n",
    "            if not books:\n",
    "                print(\"  ❌ 모든 선택자 실패 - 페이지 구조가 크게 변경되었습니다.\")\n",
    "                # 실패 시 HTML 일부 출력 (디버깅용)\n",
    "                print(\"\\n--- HTML 구조 분석 (상위 500자) ---\")\n",
    "                print(soup.prettify()[:500])\n",
    "                print(\"--- END ---\\n\")\n",
    "                continue\n",
    "            \n",
    "            # 각 도서 정보 추출\n",
    "            for idx, book in enumerate(books, 1):\n",
    "                try:\n",
    "                    # 순위 추출\n",
    "                    rank_elem = book.select_one('.num, .yes_b')\n",
    "                    rank = rank_elem.text.strip() if rank_elem else f\"{(page-1)*24 + idx}\"\n",
    "                    \n",
    "                    # 제목 추출 (Yes24는 goods_name 클래스 사용)\n",
    "                    title_elem = book.select_one('.goods_name a')\n",
    "                    title = title_elem.text.strip() if title_elem else '정보없음'\n",
    "                    \n",
    "                    # 저자/출판사 추출 (goods_info 또는 aupu 클래스)\n",
    "                    author, publisher = '정보없음', '정보없음'\n",
    "                    info_elem = book.select_one('.goods_info, .aupu')\n",
    "                    if info_elem:\n",
    "                        info_text = info_elem.get_text('|', strip=True)\n",
    "                        parts = [p.strip() for p in info_text.split('|') if p.strip()]\n",
    "                        if len(parts) >= 2:\n",
    "                            author = parts[0].replace('저자', '').replace(':', '').strip()\n",
    "                            publisher = parts[1].replace('출판사', '').replace(':', '').strip()\n",
    "                    \n",
    "                    # 판매가 추출 (yes_m 클래스)\n",
    "                    price_elem = book.select_one('.yes_m')\n",
    "                    price = price_elem.text.strip() if price_elem else '0원'\n",
    "                    \n",
    "                    # 판매지수 추출 (saleNum 클래스)\n",
    "                    sales_elem = book.select_one('.saleNum')\n",
    "                    sales_point = sales_elem.text.strip() if sales_elem else '0'\n",
    "                    \n",
    "                    # 데이터 추가\n",
    "                    books_data.append([rank, title, author, publisher, price, sales_point])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ⚠️  도서 {idx} 처리 중 오류: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  📦 페이지 {page} 처리 완료: {len(books)}개 도서\")\n",
    "            \n",
    "            # 서버 부하 방지 대기\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"  ❌ 네트워크 오류: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ 예상치 못한 오류: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 결과 저장\n",
    "    if books_data:\n",
    "        save_csv(books_data)\n",
    "        save_html(books_data)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🎉 모든 작업 완료!\")\n",
    "        print(f\"📊 수집된 도서 수: {len(books_data)}권\")\n",
    "        print(\"📁 생성된 파일:\")\n",
    "        print(\"   - ch14_yes24.csv\")\n",
    "        print(\"   - yes24_bestseller.html\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n❌ 최종: 수집된 데이터가 전혀 없습니다.\")\n",
    "        print(\"ℹ️  해결 방법:\")\n",
    "        print(\"   1. 인터넷 연결 확인\")\n",
    "        print(\"   2. 브라우저에서 해당 URL 접속 가능 여부 확인\")\n",
    "        print(\"   3. Yes24 웹사이트 구조가 크게 변경되었을 수 있습니다.\")\n",
    "    \n",
    "    return books_data\n",
    "\n",
    "def save_csv(data):\n",
    "    \"\"\"CSV 파일 저장\"\"\"\n",
    "    filename = 'ch14_yes24.csv'\n",
    "    with open(filename, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['순위', '제목', '저자', '출판사', '판매가', '판매지수'])\n",
    "        writer.writerows(data)\n",
    "    print(f\"\\n✅ CSV 저장 완료: {filename}\")\n",
    "\n",
    "def save_html(data):\n",
    "    \"\"\"HTML 파일 저장 (데이터 직접 삽입 - CORS 문제 완전 해결)\"\"\"\n",
    "    filename = 'yes24_bestseller.html'\n",
    "    \n",
    "    # Bootstrap 스타일 적용 (모던한 디자인)\n",
    "    html_content = f'''<!DOCTYPE html>\n",
    "<html lang=\"ko\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Yes24 베스트셀러 TOP {len(data)}</title>\n",
    "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        body {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; }}\n",
    "        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }}\n",
    "        h1 {{ color: #2c3e50; text-align: center; margin-bottom: 30px; font-weight: 800; }}\n",
    "        .stats {{ text-align: center; font-size: 20px; color: #7f8c8d; margin-bottom: 30px; font-weight: 500; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; }}\n",
    "        th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 12px; text-align: center; font-weight: bold; }}\n",
    "        td {{ border: 1px solid #ddd; padding: 12px; }}\n",
    "        tr:nth-child(even) {{ background-color: #f9f9f9; }}\n",
    "        tr:hover {{ background-color: #e8f5e9; transition: all 0.3s; }}\n",
    "        .text-danger {{ font-weight: bold; color: #e74c3c !important; }}\n",
    "        .text-end {{ text-align: right; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>📚 Yes24 베스트셀러</h1>\n",
    "        <div class=\"stats\">총 {len(data)}개의 도서 정보 (기준: {time.strftime('%Y-%m-%d %H:%M:%S')})</div>\n",
    "        <div class=\"table-responsive\">\n",
    "            <table class=\"table table-hover align-middle\">\n",
    "                <thead>\n",
    "                    <tr>\n",
    "                        <th class=\"text-center\">순위</th>\n",
    "                        <th>제목</th>\n",
    "                        <th>저자</th>\n",
    "                        <th>출판사</th>\n",
    "                        <th class=\"text-center\">판매가</th>\n",
    "                        <th class=\"text-center\">판매지수</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>'''\n",
    "    \n",
    "    # 데이터 행 추가 (반복문)\n",
    "    for book in data:\n",
    "        html_content += f'''\n",
    "                    <tr>\n",
    "                        <td class=\"text-center fw-bold\">{book[0]}</td>\n",
    "                        <td>{book[1]}</td>\n",
    "                        <td>{book[2]}</td>\n",
    "                        <td>{book[3]}</td>\n",
    "                        <td class=\"text-end text-danger\">{book[4]}</td>\n",
    "                        <td class=\"text-end\">{book[5]}</td>\n",
    "                    </tr>'''\n",
    "    \n",
    "    # HTML 완성\n",
    "    html_content += '''\n",
    "                </tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "        <div class=\"text-center mt-4 text-muted\">\n",
    "            <small>본 데이터는 Yes24 베스트셀러 페이지에서 수집되었습니다.</small>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>'''\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"✅ HTML 저장 완료: {filename}\")\n",
    "    print(f\"🌐 파일을 더블클릭하면 브라우저에서 바로 확인됩니다!\")\n",
    "\n",
    "# 메인 실행\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_yes24_bestseller(pages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10428612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "📚 Yes24 베스트셀러 크롤러 (봇 차단 회피 버전)\n",
      "======================================================================\n",
      "\n",
      "📥 페이지 1 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=1\n",
      "  ⏱️  서버 부하 방지 대기: 3.8초\n",
      "  페이지 제목:  국내도서 종합 베스트 - 예스24 \n",
      "  ❌ 모든 선택자 실패 - 페이지 구조 분석 필요\n",
      "  ❌ 예상치 못한 오류: 'str' object has no attribute 'attrs'\n",
      "\n",
      "📥 페이지 2 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=2\n",
      "  ⏱️  서버 부하 방지 대기: 3.3초\n",
      "  페이지 제목:  국내도서 종합 베스트 - 예스24 \n",
      "  ❌ 모든 선택자 실패 - 페이지 구조 분석 필요\n",
      "  ❌ 예상치 못한 오류: 'str' object has no attribute 'attrs'\n",
      "\n",
      "📥 페이지 3 크롤링 중: http://www.yes24.com/24/category/bestseller?PageNumber=3\n",
      "  ⏱️  서버 부하 방지 대기: 3.8초\n",
      "  페이지 제목:  국내도서 종합 베스트 - 예스24 \n",
      "  ❌ 모든 선택자 실패 - 페이지 구조 분석 필요\n",
      "  ❌ 예상치 못한 오류: 'str' object has no attribute 'attrs'\n",
      "\n",
      "======================================================================\n",
      "❌ 최종: 수집된 데이터가 전혀 없습니다.\n",
      "ℹ️  해결 방법:\n",
      "   1. 인터넷 연결 확인\n",
      "   2. 브라우저에서 http://www.yes24.com/24/category/bestseller 접속 확인\n",
      "   3. 해당 URL을 방문했을 때 도서 목록이 보이는지 확인\n",
      "   4. 보이지 않는다면 Yes24가 구조를 크게 변경함 → 코드 업데이트 필요\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "def scrape_yes24_bestseller(pages=3, debug_mode=True):\n",
    "    \"\"\"\n",
    "    Yes24 베스트셀러 정보를 수집 (봇 차단 완전 회피 버전)\n",
    "    debug_mode=True: 실패 시 전체 HTML 저장\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"📚 Yes24 베스트셀러 크롤러 (봇 차단 회피 버전)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    books_data = []\n",
    "    base_url = \"http://www.yes24.com/24/category/bestseller\"\n",
    "    \n",
    "    # Yes24 실제 구조 (2025년 11월 기준)\n",
    "    # 봇 차단 회피를 위한 헤더 (실제 브라우저처럼 보이도록)\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Referer': 'http://www.yes24.com/',\n",
    "        'Cache-Control': 'max-age=0'\n",
    "    }\n",
    "    \n",
    "    # 현재 Yes24 사용하는 선택자 (우선순위 정렬)\n",
    "    container_selectors = [\n",
    "        '#yesList > li',           # 가장 정확한 선택자\n",
    "        'ul#yesList li',           # 대체 선택자\n",
    "        '.yesGoods',               # 구 호환 선택자\n",
    "        '#categoryBestList li',    # 백업 선택자\n",
    "        '.goods_sec li'            # 최후의 선택자\n",
    "    ]\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        url = f\"{base_url}?PageNumber={page}\"\n",
    "        print(f\"\\n📥 페이지 {page} 크롤링 중: {url}\")\n",
    "        \n",
    "        try:\n",
    "            # 요청 전 랜덤 대기 (봇 탐지 회피)\n",
    "            sleep_time = random.uniform(3, 6)\n",
    "            print(f\"  ⏱️  서버 부하 방지 대기: {sleep_time:.1f}초\")\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "            # HTTP 요청\n",
    "            response = requests.get(url, headers=headers, timeout=20)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # 응답 검증\n",
    "            if len(response.text) < 5000:\n",
    "                print(\"  ⚠️ 응답 내용이 너무 적습니다 (봇 차단 의심)\")\n",
    "                if debug_mode:\n",
    "                    save_debug_html(response.text, f\"blocked_page_{page}.html\")\n",
    "                continue\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # 페이지 제목 확인\n",
    "            page_title = soup.title.text if soup.title else \"No title\"\n",
    "            print(f\"  페이지 제목: {page_title}\")\n",
    "            \n",
    "            # 본문 내용 확인\n",
    "            body_content = soup.body.get_text() if soup.body else \"\"\n",
    "            if \"베스트셀러\" not in body_content:\n",
    "                print(\"  ⚠️  본문에 '베스트셀러' 키워드 없음 (구조 변경 의심)\")\n",
    "                if debug_mode:\n",
    "                    save_debug_html(response.text, f\"structure_changed_page_{page}.html\")\n",
    "                continue\n",
    "            \n",
    "            # 책 컨테이너 찾기 (대체 선택자 순차 시도)\n",
    "            books = []\n",
    "            selected_selector = \"\"\n",
    "            \n",
    "            for selector in container_selectors:\n",
    "                books = soup.select(selector)\n",
    "                if books:\n",
    "                    selected_selector = selector\n",
    "                    print(f\"  ✅ 선택자 '{selector}'로 {len(books)}개 도서 발견\")\n",
    "                    break\n",
    "            \n",
    "            if not books:\n",
    "                print(\"  ❌ 모든 선택자 실패 - 페이지 구조 분석 필요\")\n",
    "                if debug_mode:\n",
    "                    # 자동 구조 분석 시도\n",
    "                    auto_selector = auto_detect_selector(soup)\n",
    "                    if auto_selector:\n",
    "                        print(f\"  💡 자동 감지된 선택자: {auto_selector}\")\n",
    "                        books = soup.select(auto_selector)\n",
    "                    else:\n",
    "                        save_debug_html(response.text, f\"failed_page_{page}.html\")\n",
    "                        print(\"  📄 디버그 파일 'failed_page_{page}.html' 생성됨\")\n",
    "                continue\n",
    "            \n",
    "            # 각 도서 정보 추출\n",
    "            success_count = 0\n",
    "            for idx, book in enumerate(books, 1):\n",
    "                try:\n",
    "                    # 순위\n",
    "                    rank_elem = book.select_one('.num')\n",
    "                    rank = rank_elem.text.strip() if rank_elem else f\"{(page-1)*24 + idx}\"\n",
    "                    \n",
    "                    # 제목\n",
    "                    title_elem = book.select_one('.goods_name a')\n",
    "                    title = title_elem.text.strip() if title_elem else '정보없음'\n",
    "                    \n",
    "                    # 저자/출판사\n",
    "                    author, publisher = '정보없음', '정보없음'\n",
    "                    info_elem = book.select_one('.goods_info')\n",
    "                    if info_elem:\n",
    "                        info_text = re.sub(r'\\s+', ' ', info_elem.get_text())\n",
    "                        parts = [p.strip() for p in info_text.split('|') if p.strip()]\n",
    "                        if len(parts) >= 2:\n",
    "                            author = parts[0].replace('저자', '').strip()\n",
    "                            publisher = parts[1].replace('출판사', '').strip()\n",
    "                    \n",
    "                    # 판매가\n",
    "                    price_elem = book.select_one('.yes_m')\n",
    "                    price = price_elem.text.strip() if price_elem else '0원'\n",
    "                    \n",
    "                    # 판매지수\n",
    "                    sales_elem = book.select_one('.saleNum')\n",
    "                    sales_point = sales_elem.text.strip() if sales_elem else '0'\n",
    "                    \n",
    "                    # 유효성 검사 (제목이 '정보없음'이면 무시)\n",
    "                    if title != '정보없음':\n",
    "                        books_data.append([rank, title, author, publisher, price, sales_point])\n",
    "                        success_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if debug_mode and idx <= 3:  # 첫 3개만 오류 출력\n",
    "                        print(f\"    ⚠️  도서 {idx} 처리 중 오류: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  📦 페이지 {page} 처리 완료: {success_count}개 도서 추출 성공\")\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"  ❌ 네트워크 오류: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ 예상치 못한 오류: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 최종 결과 처리\n",
    "    if books_data:\n",
    "        save_csv(books_data)\n",
    "        save_html(books_data)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"🎉 모든 작업 완료!\")\n",
    "        print(f\"📊 수집된 도서 수: {len(books_data)}권\")\n",
    "        print(\"📁 생성된 파일:\")\n",
    "        print(\"   - ch14_yes24.csv\")\n",
    "        print(\"   - yes24_bestseller.html\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"❌ 최종: 수집된 데이터가 전혀 없습니다.\")\n",
    "        print(\"ℹ️  해결 방법:\")\n",
    "        print(\"   1. 인터넷 연결 확인\")\n",
    "        print(\"   2. 브라우저에서 http://www.yes24.com/24/category/bestseller 접속 확인\")\n",
    "        print(\"   3. 해당 URL을 방문했을 때 도서 목록이 보이는지 확인\")\n",
    "        print(\"   4. 보이지 않는다면 Yes24가 구조를 크게 변경함 → 코드 업데이트 필요\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    return books_data\n",
    "\n",
    "def auto_detect_selector(soup):\n",
    "    \"\"\"\n",
    "    자동으로 도서 컨테이너 선택자 감지\n",
    "    \"\"\"\n",
    "    # 패턴 기반 검색\n",
    "    patterns = [\n",
    "        ('ul', lambda tag: 'id' in tag.attrs and 'list' in tag['id'].lower()),\n",
    "        ('div', lambda tag: 'class' in tag.attrs and any('goods' in c for c in tag['class'])),\n",
    "        ('li', lambda tag: True)  # 마지막 수단\n",
    "    ]\n",
    "    \n",
    "    for tag_name, filter_func in patterns:\n",
    "        elements = soup.find_all(tag_name, filter_func)\n",
    "        if elements and len(elements) >= 5:  # 최소 5개 이상 발견\n",
    "            first_elem = elements[0]\n",
    "            if 'id' in first_elem.attrs:\n",
    "                return f\"#{first_elem['id']} > {first_elem.find().name}\"\n",
    "            elif 'class' in first_elem.attrs:\n",
    "                return f\"{tag_name}.{first_elem['class'][0]}\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "def save_debug_html(html_content, filename):\n",
    "    \"\"\"디버깅용 HTML 파일 저장\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    print(f\"  📄 디버그 파일 '{filename}' 생성됨 - 이 파일을 분석해주세요\")\n",
    "\n",
    "def save_csv(data):\n",
    "    \"\"\"CSV 파일 저장\"\"\"\n",
    "    filename = 'ch14_yes24.csv'\n",
    "    with open(filename, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['순위', '제목', '저자', '출판사', '판매가', '판매지수'])\n",
    "        writer.writerows(data)\n",
    "    print(f\"\\n✅ CSV 저장 완료: {filename}\")\n",
    "\n",
    "def save_html(data):\n",
    "    \"\"\"HTML 파일 저장 (봇 차단 회피 + CORS 문제 완전 해결)\"\"\"\n",
    "    filename = 'yes24_bestseller.html'\n",
    "    \n",
    "    # 모던한 디자인의 HTML 템플릿\n",
    "    html_content = f'''<!DOCTYPE html>\n",
    "<html lang=\"ko\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Yes24 베스트셀러 TOP {len(data)}</title>\n",
    "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css\">\n",
    "    <style>\n",
    "        body {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; min-height: 100vh; }}\n",
    "        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); }}\n",
    "        h1 {{ color: #2c3e50; text-align: center; margin-bottom: 10px; font-weight: 800; }}\n",
    "        .stats {{ text-align: center; font-size: 22px; color: #7f8c8d; margin-bottom: 30px; font-weight: 500; }}\n",
    "        .table-responsive {{ border-radius: 10px; overflow: hidden; }}\n",
    "        th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 15px 12px; text-align: center; font-weight: bold; border: none !important; }}\n",
    "        td {{ padding: 12px; vertical-align: middle; border-color: #eee !important; }}\n",
    "        tr:hover {{ background-color: #f8f9ff; transform: scale(1.01); transition: all 0.2s; }}\n",
    "        .text-danger {{ font-weight: bold; color: #e74c3c !important; }}\n",
    "        .badge-rank {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 6px 12px; border-radius: 20px; font-weight: bold; }}\n",
    "        .footer {{ text-align: center; margin-top: 30px; color: #95a5a6; font-size: 14px; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1><i class=\"bi bi-book\"></i> Yes24 베스트셀러</h1>\n",
    "        <div class=\"stats\">총 {len(data)}개의 도서 정보</div>\n",
    "        <div class=\"table-responsive\">\n",
    "            <table class=\"table table-hover align-middle\">\n",
    "                <thead>\n",
    "                    <tr>\n",
    "                        <th class=\"text-center\"><i class=\"bi bi-trophy\"></i> 순위</th>\n",
    "                        <th><i class=\"bi bi-book-fill\"></i> 제목</th>\n",
    "                        <th><i class=\"bi bi-person\"></i> 저자</th>\n",
    "                        <th><i class=\"bi bi-building\"></i> 출판사</th>\n",
    "                        <th class=\"text-center\"><i class=\"bi bi-currency-dollar\"></i> 판매가</th>\n",
    "                        <th class=\"text-center\"><i class=\"bi bi-graph-up\"></i> 판매지수</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>'''\n",
    "    \n",
    "    # 데이터 행 추가\n",
    "    rows_html = ''\n",
    "    for i, book in enumerate(data, 1):\n",
    "        # 상위 3위 강조\n",
    "        rank_badge = f'<span class=\"badge-rank\">{book[0]}</span>' if int(book[0]) <= 3 else book[0]\n",
    "        \n",
    "        rows_html += f'''\n",
    "                    <tr>\n",
    "                        <td class=\"text-center\">{rank_badge}</td>\n",
    "                        <td><strong>{book[1]}</strong></td>\n",
    "                        <td>{book[2]}</td>\n",
    "                        <td>{book[3]}</td>\n",
    "                        <td class=\"text-end text-danger\">{book[4]}</td>\n",
    "                        <td class=\"text-end\">{book[5]}</td>\n",
    "                    </tr>'''\n",
    "    \n",
    "    # HTML 완성\n",
    "    html_content += rows_html + '''\n",
    "                </tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "        <div class=\"footer\">\n",
    "            <i class=\"bi bi-clock\"></i> 생성 시간: ''' + time.strftime('%Y-%m-%d %H:%M:%S') + '''\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>'''\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"✅ HTML 저장 완료: {filename}\")\n",
    "    print(f\"🌐 파일을 더블클릭하면 브라우저에서 바로 확인됩니다!\")\n",
    "\n",
    "# 메인 실행\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_yes24_bestseller(pages=3, debug_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a241e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c5fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf48bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d477dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee3cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de78933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a2a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f652602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5220c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1a09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a6f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee14a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef19b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc660dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508d650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9337b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06fb71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebf98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7d8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798c406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ed929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152393b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833812f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9515f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b6ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e1e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4192952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298e061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3c522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0dbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa0309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
